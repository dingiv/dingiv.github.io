import{_ as e,c as a,o as d,ae as r}from"./chunks/framework.CDjunVez.js";const A=JSON.parse('{"title":"加速技术","description":"","frontmatter":{"title":"加速技术","order":60},"headers":[],"relativePath":"ai/acc/index.md","filePath":"ai/acc/index.md"}'),o={name:"ai/acc/index.md"};function n(h,t,l,i,p,c){return d(),a("div",null,[...t[0]||(t[0]=[r('<h1 id="科学计算加速技术" tabindex="-1">科学计算加速技术 <a class="header-anchor" href="#科学计算加速技术" aria-label="Permalink to &quot;科学计算加速技术&quot;">​</a></h1><p>目前的 AI 训练需要大量的计算资源，是阻碍 AI 发展的重大绊脚石。通过计算加速技术提高大模型训练和部署的资源需求，从而大力推动 AI 进化和商业化落地。</p><h1 id="硬件加速" tabindex="-1">硬件加速 <a class="header-anchor" href="#硬件加速" aria-label="Permalink to &quot;硬件加速&quot;">​</a></h1><p>使用 GPU 的加速可并行执行的计算任务，目前主要包括俩个领域：图形渲染和科学计算。人工智能领域主要使用科学计算 API 进行加速。</p><p>然而，硬件加速的现状并不乐观，各个硬件厂商纷纷使用自家独立的 GPU API，并且同是自家的 API 同样也被迭代和变更，导致不同的硬件设备的差异直接就被暴露到了应用层。应用层的软件编写者需要直面硬件差异。</p><blockquote><p>OpenCL</p><p>曾经的 GPU 跨平台统一 API，但是随着各家的硬件生态不断割裂，分歧再次扩大，OpenCL 已逐渐退出历史舞台，但仍然被 AMD 和 Intel 所支持，不过性能往往不如各家的专用 API。</p></blockquote><h2 id="硬件-api" tabindex="-1">硬件 API <a class="header-anchor" href="#硬件-api" aria-label="Permalink to &quot;硬件 API&quot;">​</a></h2><table tabindex="0"><thead><tr><th>厂商</th><th>图形 API</th><th>通用计算 API</th></tr></thead><tbody><tr><td>Apple（苹果）</td><td>Metal Graphics</td><td>Metal Compute（+ Core ML / ANE）</td></tr><tr><td>NVIDIA（英伟达）</td><td>OpenGL / Vulkan / DirectX</td><td>CUDA（核心）</td></tr><tr><td>AMD（超微）</td><td>OpenGL / Vulkan / DirectX</td><td>ROCm（Radeon Open Compute）</td></tr><tr><td>Intel</td><td>OpenGL / Vulkan / DirectX</td><td>oneAPI（DPC++ / SYCL）</td></tr></tbody></table><h2 id="torch" tabindex="-1">Torch <a class="header-anchor" href="#torch" aria-label="Permalink to &quot;Torch&quot;">​</a></h2><p>Torch 框架为了使用硬件加速计算，主动实现各个 GPU 厂商的封装层，将各家的硬件 API 进行屏蔽，从而让上层的数据科学家无需触及糟心而混乱的 GPU 生态，专注于数据训练即可，在调用 torch 的 API 时，torch 将自动识别当前的硬件环境，使用对应的硬件进行加速，当前支持的硬件平台包括：</p><table tabindex="0"><thead><tr><th>平台</th><th>后端</th><th>底层调用</th></tr></thead><tbody><tr><td>NVIDIA GPU</td><td>CUDA</td><td>cuBLAS、cuDNN、TensorRT</td></tr><tr><td>AMD GPU</td><td>ROCm</td><td>hipBLAS、MIOpen</td></tr><tr><td>Apple M 芯片</td><td>MPS （Metal Performance Shaders）</td><td>Metal Compute</td></tr><tr><td>Intel GPU / CPU</td><td>XPU （oneAPI）</td><td>oneDNN</td></tr><tr><td>CPU</td><td>Native</td><td>OpenMP / MKL / BLAS</td></tr></tbody></table><h2 id="并行化" tabindex="-1">并行化 <a class="header-anchor" href="#并行化" aria-label="Permalink to &quot;并行化&quot;">​</a></h2><p>vllm ，deepspeed，llama.cpp</p>',13)])])}const s=e(o,[["render",n]]);export{A as __pageData,s as default};
