import{_ as s,o as l,c as e,j as Q,a as T,ah as a,ao as n}from"./chunks/framework.D8J2w7BQ.js";const B=JSON.parse('{"title":"监督学习","description":"","frontmatter":{},"headers":[],"relativePath":"ai/neural/ml/supervised.md","filePath":"ai/neural/ml/supervised.md"}'),o={name:"ai/neural/ml/supervised.md"},d={tabindex:"0"},r={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},m={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.048ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.705ex",height:"1.934ex",role:"img",focusable:"false",viewBox:"0 -833.9 1195.6 854.9","aria-hidden":"true"},i={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},p={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.597ex",height:"2.009ex",role:"img",focusable:"false",viewBox:"0 -694 1589.7 888","aria-hidden":"true"},h={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.464ex"},xmlns:"http://www.w3.org/2000/svg",width:"33.799ex",height:"2.034ex",role:"img",focusable:"false",viewBox:"0 -694 14939.1 899","aria-hidden":"true"},u={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},H={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.912ex"},xmlns:"http://www.w3.org/2000/svg",width:"32.223ex",height:"2.869ex",role:"img",focusable:"false",viewBox:"0 -864.9 14242.6 1267.9","aria-hidden":"true"},w={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},x={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.047ex",height:"1.946ex",role:"img",focusable:"false",viewBox:"0 -666 3114.6 860","aria-hidden":"true"},L={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},f={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.628ex"},xmlns:"http://www.w3.org/2000/svg",width:"23.455ex",height:"2.851ex",role:"img",focusable:"false",viewBox:"0 -982.5 10367.1 1260","aria-hidden":"true"},y={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},k={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-1.236ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.92ex",height:"3.193ex",role:"img",focusable:"false",viewBox:"0 -864.9 1732.6 1411.3","aria-hidden":"true"},M={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},V={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.666ex"},xmlns:"http://www.w3.org/2000/svg",width:"30.619ex",height:"2.552ex",role:"img",focusable:"false",viewBox:"0 -833.9 13533.8 1128.2","aria-hidden":"true"},c={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},Z={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.698ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.068ex",height:"2.398ex",role:"img",focusable:"false",viewBox:"0 -751.5 1356 1060","aria-hidden":"true"},b={tabindex:"0",class:"MathJax",jax:"SVG",display:"true",style:{direction:"ltr",display:"block","text-align":"center",margin:"1em 0",position:"relative"}},v={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-2.864ex"},xmlns:"http://www.w3.org/2000/svg",width:"29.36ex",height:"6.784ex",role:"img",focusable:"false",viewBox:"0 -1733 12977.3 2998.7","aria-hidden":"true"};function D(C,t,_,S,j,A){return l(),e("div",null,[t[59]||(t[59]=Q("h1",{id:"监督学习",tabindex:"-1"},[T("监督学习 "),Q("a",{class:"header-anchor",href:"#监督学习","aria-label":"Permalink to “监督学习”"},"​")],-1)),t[60]||(t[60]=Q("p",null,"监督学习的训练数据带有标签，监督学习的训练目标是学习特征 → 标签的映射。监督学习主要包括分类和回归两种子类。",-1)),t[61]||(t[61]=Q("p",null,'回归使用函数来拟合因变量和自变量之间的关系，适合于标签是连续的数值；而有些标签并不是连续数值，例如，判断一个零件质量是否合格，该标签是一个典型的二值枚举，仅包含 "是" 和 "否" 两种结果，此外，还有多分类（如图像识别）。',-1)),Q("table",d,[t[8]||(t[8]=Q("thead",null,[Q("tr",null,[Q("th",null,"项目"),Q("th",null,"分类（Classification）"),Q("th",null,"回归（Regression）")])],-1)),Q("tbody",null,[t[5]||(t[5]=Q("tr",null,[Q("td",null,"输出类型"),Q("td",null,"离散类别（如“是/否”、1/2/3）"),Q("td",null,"连续数值（如100.5、-3.2）")],-1)),t[6]||(t[6]=Q("tr",null,[Q("td",null,"决策边界"),Q("td",null,"分割类别边界"),Q("td",null,"拟合连续曲线/曲面")],-1)),t[7]||(t[7]=Q("tr",null,[Q("td",null,"典型问题"),Q("td",null,"邮件分类、疾病诊断、图像识别"),Q("td",null,"房价预测、销量预测、温度预测")],-1)),Q("tr",null,[t[3]||(t[3]=Q("td",null,"评估指标",-1)),t[4]||(t[4]=Q("td",null,"准确率、精确率、召回率、F1、AUC",-1)),Q("td",null,[t[2]||(t[2]=T("MSE、RMSE、MAE、",-1)),Q("mjx-container",r,[(l(),e("svg",m,[...t[0]||(t[0]=[a("",1)])])),t[1]||(t[1]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msup",null,[Q("mi",null,"R"),Q("mn",null,"2")])])],-1))])])])])]),t[62]||(t[62]=Q("p",null,[T("不同的算法实现方式不同，但是有相同的核心任务，那就是在训练数据上学习一个函数 f，使得在新数据上预测尽可能准确（泛化能力强）。这些算法中，有一些从一开始便已经判断出数据之间具有的函数关系的形式，只是函数中的某些位置的上的参数不确定，典型的如线性回归，在一开始，我们便已经确定了某个参数就是类似于线性关系的模式，不确定的是这个线性函数中的 w 和 b 参数。为此，可以将模型分为"),Q("strong",null,"有参模型和无参模型"),T("。有参模型往往需要大量的数据统计进行训练，从而拟合出模型的中的可变参数；无参模型，仅需进行少量的训练或者无需训练，即可通过现场归纳数据进行预测。")],-1)),t[63]||(t[63]=Q("p",null,"模型哲学：有参 vs 无参",-1)),Q("ul",null,[Q("li",null,[t[11]||(t[11]=T("有参模型 (Parametric)：预设了函数形式（如线性关系），通过数据估计有限数量的参数（如 ",-1)),Q("mjx-container",i,[(l(),e("svg",p,[...t[9]||(t[9]=[a("",1)])])),t[10]||(t[10]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mi",null,"w"),Q("mo",null,","),Q("mi",null,"b")])],-1))]),t[12]||(t[12]=T("）。优点是速度快，缺点是模型容量受限。典型代表：线性回归、逻辑回归。",-1))]),t[13]||(t[13]=Q("li",null,"无参模型 (Non-parametric)：不预设固定的函数形式，模型复杂度随数据量增长。优点是灵活，缺点是计算开销大。典型代表：KNN、决策树。",-1))]),t[64]||(t[64]=Q("h2",{id:"有参算法",tabindex:"-1"},[T("有参算法 "),Q("a",{class:"header-anchor",href:"#有参算法","aria-label":"Permalink to “有参算法”"},"​")],-1)),t[65]||(t[65]=Q("h3",{id:"线性回归",tabindex:"-1"},[T("线性回归 "),Q("a",{class:"header-anchor",href:"#线性回归","aria-label":"Permalink to “线性回归”"},"​")],-1)),t[66]||(t[66]=Q("p",null,"线性回归是最基本的数据分析模型，它假设自变量和因变量之间具有一个简单的函数关系，用直线/超平面拟合变量之间规律。这种方法在高中的课本上就已经教授过。",-1)),Q("ul",null,[t[17]||(t[17]=Q("li",null,"任务：回归。",-1)),Q("li",null,[t[16]||(t[16]=T("模型：",-1)),Q("mjx-container",h,[(l(),e("svg",g,[...t[14]||(t[14]=[a("",1)])])),t[15]||(t[15]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mi",null,"y"),Q("mo",null,"="),Q("msub",null,[Q("mi",null,"w"),Q("mn",null,"1")]),Q("msub",null,[Q("mi",null,"x"),Q("mn",null,"1")]),Q("mo",null,"+"),Q("msub",null,[Q("mi",null,"w"),Q("mn",null,"2")]),Q("msub",null,[Q("mi",null,"x"),Q("mn",null,"2")]),Q("mo",null,"+"),Q("mo",null,"⋯"),Q("mo",null,"+"),Q("msub",null,[Q("mi",null,"w"),Q("mi",null,"n")]),Q("msub",null,[Q("mi",null,"x"),Q("mi",null,"n")]),Q("mo",null,"+"),Q("mi",null,"b")])],-1))])]),t[18]||(t[18]=Q("li",null,"损失：均方误差",-1)),t[19]||(t[19]=Q("li",null,"优缺点：简单、可解释、计算快。线性假设，对异常值敏感。可以通过岭回归（L2正则）、Lasso（L1正则）防过拟合。",-1))]),t[67]||(t[67]=Q("p",null,[T("线性回归的求解方式基于"),Q("a",{href:"./loss"},"损失函数"),T("的概念，主要有两种方式：最小二乘法（公式法）或者梯度下降法，其中，最小二乘法是纯数学的实现方式，而梯度下降法是我们软件或计算机行业具体落地的时候的实践方式。")],-1)),t[68]||(t[68]=Q("h3",{id:"逻辑回归",tabindex:"-1"},[T("逻辑回归 "),Q("a",{class:"header-anchor",href:"#逻辑回归","aria-label":"Permalink to “逻辑回归”"},"​")],-1)),t[69]||(t[69]=Q("p",null,"逻辑回归是一种仿照通过线性回归改造的用于分类的算法，尽管它叫回归。",-1)),Q("ul",null,[t[27]||(t[27]=Q("li",null,[T("任务：分类（常二分类）。基于线性回归 + Sigmoid，将输出转为 "),Q("code",null,"[0,1]"),T(" 概率。")],-1)),Q("li",null,[t[24]||(t[24]=T("模型：",-1)),Q("mjx-container",u,[(l(),e("svg",H,[...t[20]||(t[20]=[a("",1)])])),t[21]||(t[21]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mi",null,"z"),Q("mo",null,"="),Q("mi",null,"w"),Q("mo",null,"⋅"),Q("mi",null,"x"),Q("mo",null,"+"),Q("mi",null,"b"),Q("mo",null,","),Q("mstyle",{scriptlevel:"0"},[Q("mspace",{width:"1em"})]),Q("mi",null,"p"),Q("mo",null,"="),Q("mi",null,"σ"),Q("mo",{stretchy:"false"},"("),Q("mi",null,"z"),Q("mo",{stretchy:"false"},")"),Q("mo",null,"="),Q("mfrac",null,[Q("mn",null,"1"),Q("mrow",null,[Q("mn",null,"1"),Q("mo",null,"+"),Q("msup",null,[Q("mi",null,"e"),Q("mrow",{"data-mjx-texclass":"ORD"},[Q("mo",null,"−"),Q("mi",null,"z")])])])])])],-1))]),t[25]||(t[25]=T("，预测：",-1)),Q("mjx-container",w,[(l(),e("svg",x,[...t[22]||(t[22]=[a("",1)])])),t[23]||(t[23]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mi",null,"p"),Q("mo",null,"≥"),Q("mn",null,"0.5")])],-1))]),t[26]||(t[26]=T(" → 正类。",-1))]),t[28]||(t[28]=Q("li",null,"损失：交叉熵",-1)),t[29]||(t[29]=Q("li",null,"优缺点：输出概率、可解释、快、适合高维。线性决策边界、多分类需One-vs-Rest。",-1)),t[30]||(t[30]=Q("li",null,"适用：垃圾邮件、疾病诊断。",-1))]),t[70]||(t[70]=Q("h2",{id:"无参算法",tabindex:"-1"},[T("无参算法 "),Q("a",{class:"header-anchor",href:"#无参算法","aria-label":"Permalink to “无参算法”"},"​")],-1)),t[71]||(t[71]=Q("h3",{id:"knn",tabindex:"-1"},[T("KNN "),Q("a",{class:"header-anchor",href:"#knn","aria-label":"Permalink to “KNN”"},"​")],-1)),t[72]||(t[72]=Q("p",null,"K近邻算法是一种简单、直观且经典的机器学习算法，属于懒惰学习（lazy learning），即训练阶段几乎不做任何计算，只存储数据；预测时才进行计算。",-1)),t[73]||(t[73]=Q("p",null,"根据测试样本在特征空间中最接近的 K 个训练样本的类别（或值），来预测测试样本的类别（分类）或数值（回归）。该算法体现了一个思想：近朱者赤，近墨者黑。我们会通过观察一个“人”周围的朋友来判断这个“人”的好坏。",-1)),Q("ul",null,[t[35]||(t[35]=Q("li",null,"任务：分类或者回归均可以。分类：少数服从多数（投票）；回归：取 K 个邻居的平均值（或加权平均）；",-1)),Q("li",null,[t[33]||(t[33]=T("模型：欧氏距离 ",-1)),Q("mjx-container",L,[(l(),e("svg",f,[...t[31]||(t[31]=[a("",1)])])),t[32]||(t[32]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mi",null,"d"),Q("mo",{stretchy:"false"},"("),Q("mi",null,"x"),Q("mo",null,","),Q("mi",null,"y"),Q("mo",{stretchy:"false"},")"),Q("mo",null,"="),Q("msqrt",null,[Q("mo",{"data-mjx-texclass":"OP"},"∑"),Q("mo",{stretchy:"false"},"("),Q("msub",null,[Q("mi",null,"x"),Q("mi",null,"i")]),Q("mo",null,"−"),Q("msub",null,[Q("mi",null,"y"),Q("mi",null,"i")]),Q("msup",null,[Q("mo",{stretchy:"false"},")"),Q("mn",null,"2")])])])],-1))]),t[34]||(t[34]=T("。",-1))]),t[36]||(t[36]=Q("li",null,"超参数：K值（小→过拟合，大→欠拟合，用交叉验证调优）。",-1)),t[37]||(t[37]=Q("li",null,"优缺点：简单、非线性、对分布无假设。计算慢（O(n)）、存储全数据、高维差、需标准化。",-1)),t[38]||(t[38]=Q("li",null,"适用：小数据集、基线模型。",-1))]),t[74]||(t[74]=a("",6)),Q("ul",null,[t[47]||(t[47]=Q("li",null,"任务：分类/回归。找最大间隔超平面分割类别。",-1)),Q("li",null,[t[41]||(t[41]=T("硬间隔：线性可分，最大化",-1)),Q("mjx-container",y,[(l(),e("svg",k,[...t[39]||(t[39]=[a("",1)])])),t[40]||(t[40]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mfrac",null,[Q("mn",null,"2"),Q("mrow",null,[Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),Q("mi",null,"w"),Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|")])])])],-1))]),t[42]||(t[42]=T("。",-1))]),t[48]||(t[48]=Q("li",null,"软间隔：引入松弛变量+铰链损失，容忍噪声。",-1)),Q("li",null,[t[45]||(t[45]=T("核技巧：RBF核",-1)),Q("mjx-container",M,[(l(),e("svg",V,[...t[43]||(t[43]=[a("",1)])])),t[44]||(t[44]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("mi",null,"K"),Q("mo",{stretchy:"false"},"("),Q("msub",null,[Q("mi",null,"x"),Q("mi",null,"i")]),Q("mo",null,","),Q("msub",null,[Q("mi",null,"x"),Q("mi",null,"j")]),Q("mo",{stretchy:"false"},")"),Q("mo",null,"="),Q("mi",null,"exp"),Q("mo",{"data-mjx-texclass":"NONE"},"⁡"),Q("mo",{stretchy:"false"},"("),Q("mo",null,"−"),Q("mi",null,"γ"),Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),Q("msub",null,[Q("mi",null,"x"),Q("mi",null,"i")]),Q("mo",null,"−"),Q("msub",null,[Q("mi",null,"x"),Q("mi",null,"j")]),Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),Q("msup",null,[Q("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),Q("mn",null,"2")]),Q("mo",{stretchy:"false"},")")])],-1))]),t[46]||(t[46]=T(" 处理非线性。",-1))]),t[49]||(t[49]=Q("li",null,"优点：泛化强、少样本有效、高维好。",-1)),t[50]||(t[50]=Q("li",null,"缺点：训练慢（O(n^2/n^3)）、参数调优难、不可解释。",-1)),t[51]||(t[51]=Q("li",null,"适用：文本分类、图像。",-1))]),t[75]||(t[75]=a("",7)),Q("ul",null,[t[56]||(t[56]=Q("li",null,"样本随机抽样 (Bootstrap Aggregating)：从原始训练集中，通过有放回抽样（Bootstrap）选出一部分样本。这意味着某些样本可能在一棵树中出现多次，而有些则从未出现（这些未被选中的约 36.8% 的数据称为 袋外数据 OOB，可用于自我验证）。",-1)),Q("li",null,[t[54]||(t[54]=T("特征随机抽样：在决策树的每个节点分裂时，算法并不从所有特征中寻找最优解，而是随机选取特征子集（通常是 ",-1)),Q("mjx-container",c,[(l(),e("svg",Z,[...t[52]||(t[52]=[a("",1)])])),t[53]||(t[53]=Q("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[Q("msqrt",null,[Q("mi",null,"p")])])],-1))]),t[55]||(t[55]=T(" 个特征），从中选出最佳分裂特征。",-1))])]),t[76]||(t[76]=a("",4)),Q("mjx-container",b,[(l(),e("svg",v,[...t[57]||(t[57]=[a("",1)])])),t[58]||(t[58]=Q("mjx-assistive-mml",{unselectable:"on",display:"block",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",overflow:"hidden",width:"100%"}},[Q("math",{xmlns:"http://www.w3.org/1998/Math/MathML",display:"block"},[Q("mi",null,"O"),Q("mi",null,"b"),Q("mi",null,"j"),Q("mo",null,"="),Q("munderover",null,[Q("mo",{"data-mjx-texclass":"OP"},"∑"),Q("mrow",{"data-mjx-texclass":"ORD"},[Q("mi",null,"i"),Q("mo",null,"="),Q("mn",null,"1")]),Q("mi",null,"m")]),Q("mi",null,"l"),Q("mo",{stretchy:"false"},"("),Q("msub",null,[Q("mi",null,"y"),Q("mi",null,"i")]),Q("mo",null,","),Q("msub",null,[Q("mrow",{"data-mjx-texclass":"ORD"},[Q("mover",null,[Q("mi",null,"y"),Q("mo",{stretchy:"false"},"^")])]),Q("mi",null,"i")]),Q("mo",{stretchy:"false"},")"),Q("mo",null,"+"),Q("munderover",null,[Q("mo",{"data-mjx-texclass":"OP"},"∑"),Q("mrow",{"data-mjx-texclass":"ORD"},[Q("mi",null,"k"),Q("mo",null,"="),Q("mn",null,"1")]),Q("mi",null,"K")]),Q("mi",{mathvariant:"normal"},"Ω"),Q("mo",{stretchy:"false"},"("),Q("msub",null,[Q("mi",null,"f"),Q("mi",null,"k")]),Q("mo",{stretchy:"false"},")")])],-1))]),t[77]||(t[77]=a("",7))])}const R=s(o,[["render",D]]);export{B as __pageData,R as default};
