import{_ as s,o as i,c as e,ah as t}from"./chunks/framework.BwbIerCg.js";const c=JSON.parse('{"title":"FSDP","description":"","frontmatter":{"title":"FSDP"},"headers":[],"relativePath":"ai/compute/engine/fsdp.md","filePath":"ai/compute/engine/fsdp.md"}'),l={name:"ai/compute/engine/fsdp.md"};function h(n,a,r,p,d,k){return i(),e("div",null,[...a[0]||(a[0]=[t(`<h1 id="fsdp" tabindex="-1">FSDP <a class="header-anchor" href="#fsdp" aria-label="Permalink to “FSDP”">​</a></h1><p>Fully Sharded Data Parallel (FSDP) 是 PyTorch 2.0 原生引入的分布式训练方案，功能上对标 DeepSpeed ZeRO，但与 PyTorch 生态深度集成，通过 torch.compile、torch.autograd 实现自动分片和通信算子融合。</p><h2 id="与-zero-的关系" tabindex="-1">与 ZeRO 的关系 <a class="header-anchor" href="#与-zero-的关系" aria-label="Permalink to “与 ZeRO 的关系”">​</a></h2><p>FSDP 的设计借鉴了 ZeRO-3，同样将参数、梯度、优化器状态全部分片。但实现上更贴近 PyTorch 的设计哲学：通过 <code>torch.distributed.fsdp.FullyShardedDataParallel</code> 包装模块，自动处理前向传播时的 AllGather 和反向传播后的 ReduceScatter。这种模块化设计使得迁移现有代码非常简单——只需将 <code>nn.DataParallel</code> 替换为 <code>FSDP</code>，无需重构模型定义。</p><h2 id="混合精度" tabindex="-1">混合精度 <a class="header-anchor" href="#混合精度" aria-label="Permalink to “混合精度”">​</a></h2><p>FSDP 原生支持 BF16（Brain Float 16）混合精度训练。BF16 与 FP16 的指数位相同（8 位），但尾数位减少到 7 位，相比 FP16 的 10 位尾数，精度略有损失但数值范围更大，不需要 loss scaling。对于训练稳定性敏感的大模型，BF16 是更安全的选择。PyTorch 2.0 引入的 <code>torch.float16</code> + <code>GradScaler</code> 也支持 FP16 训练，但需要手动调整 loss scale。</p><h2 id="通信优化" tabindex="-1">通信优化 <a class="header-anchor" href="#通信优化" aria-label="Permalink to “通信优化”">​</a></h2><p>FSDP 的通信调度经过精心设计。前向传播时，参数 AllGather 与前一层计算流水线重叠（overlap）；反向传播时，梯度 ReduceScatter 与下一层反向流水线重叠。这种&quot;通信计算隐藏&quot;策略将通信开销从串行的 30% 降至并行的 10% 以下。</p><h2 id="使用方式" tabindex="-1">使用方式 <a class="header-anchor" href="#使用方式" aria-label="Permalink to “使用方式”">​</a></h2><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.distributed.fsdp </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> FullyShardedDataParallel </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> FSDP</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> transformers </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoModelForCausalLM</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> AutoModelForCausalLM.from_pretrained(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;meta-llama/Llama-2-7b&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">model </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> FSDP(model, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">sharding_strategy</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;FULL_SHARD&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mixed_precision</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;bf16&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre></div><p>FSDP 的 API 比 DeepSpeed 更简洁，适合已熟悉 PyTorch DDP 的开发者。但 ZeRO 的成熟度和文档丰富度仍然更高，对于生产环境的大规模训练，DeepSpeed 仍是首选。</p>`,11)])])}const E=s(l,[["render",h]]);export{c as __pageData,E as default};
