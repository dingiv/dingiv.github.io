import{_ as o,o as a,c as l,ah as Q,j as t,a as T}from"./chunks/framework.BvDvRtye.js";const C=JSON.parse('{"title":"主流引擎","description":"","frontmatter":{"title":"主流引擎","order":10},"headers":[],"relativePath":"ai/compute/engine/index.md","filePath":"ai/compute/engine/index.md"}'),n={name:"ai/compute/engine/index.md"},s={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},r={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.832ex",height:"2.452ex",role:"img",focusable:"false",viewBox:"0 -833.9 2577.6 1083.9","aria-hidden":"true"},i={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},d={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.618ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 2041 1000","aria-hidden":"true"},m={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},p={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.618ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 2041 1000","aria-hidden":"true"},h={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},x={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.489ex",height:"1.532ex",role:"img",focusable:"false",viewBox:"0 -666 1100 677","aria-hidden":"true"},g={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.357ex",height:"1.025ex",role:"img",focusable:"false",viewBox:"0 -442 600 453","aria-hidden":"true"},w={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.186ex"},xmlns:"http://www.w3.org/2000/svg",width:"9.042ex",height:"1.731ex",role:"img",focusable:"false",viewBox:"0 -683 3996.6 765","aria-hidden":"true"},f={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},L={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.371ex",height:"1.595ex",role:"img",focusable:"false",viewBox:"0 -683 1048 705","aria-hidden":"true"},b={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},k={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"9.874ex",height:"1.902ex",role:"img",focusable:"false",viewBox:"0 -683 4364.5 840.8","aria-hidden":"true"};function v(y,e,M,H,P,_){return a(),l("div",null,[e[28]||(e[28]=Q('<h1 id="主流引擎" tabindex="-1">主流引擎 <a class="header-anchor" href="#主流引擎" aria-label="Permalink to “主流引擎”">​</a></h1><p>AI 计算引擎分为推理引擎和训练引擎两大类。推理引擎关注如何在给定模型权重后高效生成输出，训练引擎关注如何高效地将大模型训练过程分布式化到多张 GPU 甚至多台机器上。</p><h2 id="推理引擎" tabindex="-1">推理引擎 <a class="header-anchor" href="#推理引擎" aria-label="Permalink to “推理引擎”">​</a></h2><p>推理的特点是只做前向传播、对延迟敏感、需要处理变长序列、并发请求多样。这些差异催生了与训练引擎截然不同的优化技术栈。</p><table tabindex="0"><thead><tr><th>框架</th><th>核心技术</th><th>适用场景</th><th>详细介绍</th></tr></thead><tbody><tr><td>vLLM</td><td>PagedAttention、连续批处理</td><td>高吞吐在线服务、长序列</td><td><a href="./vllm">vLLM</a></td></tr><tr><td>TGI</td><td>FlashAttention、量化基准</td><td>HuggingFace 模型部署、生产环境</td><td><a href="./other#tgi">TGI</a></td></tr><tr><td>TensorRT-LLM</td><td>算子融合、INT4/INT8 量化</td><td>NVIDIA GPU、极致性能</td><td><a href="./other#tensorrt-llm">TensorRT-LLM</a></td></tr><tr><td>llama.cpp</td><td>CPU/GPU 混合推理、GGUF 量化</td><td>本地部署、资源受限环境</td><td><a href="./other#llamacpp">llama.cpp</a></td></tr><tr><td>SGLang</td><td>RadixAttention、结构化并发</td><td>多轮对话、复杂 prompt</td><td><a href="./other#sglang">SGLang</a></td></tr></tbody></table><h3 id="核心挑战" tabindex="-1">核心挑战 <a class="header-anchor" href="#核心挑战" aria-label="Permalink to “核心挑战”">​</a></h3><p>推理的首要挑战是<strong>延迟</strong>，而非吞吐量。用户等待 ChatGPT 返回首个 Token 的时间（TTFT，Time To First Token）直接决定体验，这要求推理引擎优化单请求的端到端延迟，而非简单地提升 batch size。vLLM 通过 PagedAttention 引入细粒度 KV Cache 管理，将 TTFT 降低了 2-3 倍。</p><p>显存占用是另一大瓶颈。训练完成后，模型权重和优化器状态可丢弃，但推理时 KV Cache 会随序列长度线性增长。一个 7B 模型在 2048 长度、batch size 32 时，KV Cache 约需 8GB（FP16），超过权重本身。TGI（Text Generation Inference）通过 FlashAttention 减少内存碎片，vLLM 通过 PagedKV 支持显存不足时的部分 offload 到 CPU。</p><p>并发请求的调度也很复杂。不同请求的序列长度差异巨大，短序列完成后释放的显存需要分配给新请求，而长序列的 KV Cache 需要持续保留。连续批处理（continuous batching）是 2023 年的关键技术——当 batch 中的某个序列生成结束时，立即插入新序列，而非等待整个 batch 完成。这可将吞吐量提升 3-10 倍。</p><h3 id="优化技术" tabindex="-1">优化技术 <a class="header-anchor" href="#优化技术" aria-label="Permalink to “优化技术”">​</a></h3>',10)),t("p",null,[e[2]||(e[2]=T("KV Cache 优化是推理性能的核心。标准 Attention 需要缓存所有历史位置的 Key 和 Value 张量，每次生成新 Token 时与历史 KV 做矩阵乘法，计算复杂度为 ",-1)),t("mjx-container",s,[(a(),l("svg",r,[...e[0]||(e[0]=[Q('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="msup" transform="translate(1152,0)"><g data-mml-node="mi"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(633,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(2188.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),e[1]||(e[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"O"),t("mo",{stretchy:"false"},"("),t("msup",null,[t("mi",null,"n"),t("mn",null,"2")]),t("mo",{stretchy:"false"},")")])],-1))]),e[3]||(e[3]=T("。FlashAttention 通过分块计算减少内存访问次数，将显存带宽利用率从 20% 提升到 80% 以上，推理速度提升 2-3 倍。PagedAttention 进一步将 KV Cache 分页管理，支持显存不足时的动态换页和共享。",-1))]),e[29]||(e[29]=Q('<p>算子融合通过将多个连续算子合并为一个 CUDA kernel 来减少显存访问。例如 LayerNorm 后接 Residual 可融合为一个 kernel，只需读写一次显存，而非两次。TensorRT-LLM 通过图优化自动识别可融合算子，推理延迟降低 15-30%。</p><p>量化是降低显存占用和计算量的利器。将 FP16 权重量化为 INT8 可将显存减半，INT4 减为四分之一，配合 INT8/INT4 算子可实现接近原始精度的性能。GPTQ、AWQ、SpQR 等量化算法通过最小化权重误差或激活误差，在 4-bit 量化下仍保持 PPL 接近 FP16。llama.cpp 是量化推理的代表，支持在 CPU 上运行量化后的 LLaMA 模型。</p><p>投机采样（speculative decoding）通过一个小模型（如 1B 参数）快速生成多个 Token，然后由大模型并行验证，若验证通过则保留，否则回退重新生成。这在大模型的慢速生成和小模型的快速生成间取得了平衡，可将生成速度提升 2-3 倍。前提是需要训练一个与主模型分布一致的投机模型。</p><p>除了上述框架中的核心技术外，推理引擎还依赖以下优化技术：</p><ul><li><strong>模型并行</strong> - 张量并行与流水线并行的分布式推理与训练</li><li><strong>投机采样</strong> - 通过小模型辅助大模型加速生成</li><li><strong>参数高效微调</strong> - 通过少量参数调整适配模型到特定任务</li><li><strong>量化推理</strong> - INT8/INT4 量化降低显存占用</li><li><strong>混合专家</strong> - 稀疏激活打破参数量与计算量的耦合</li></ul><p>选择推理框架需要考虑硬件平台（NVIDIA GPU vs CPU vs Apple Silicon）、部署规模（单机 vs 集群）、延迟要求（在线服务 vs 离线批处理）。vLLM 和 TGI 在 NVIDIA GPU 上性能最强，llama.cpp 适合本地部署，TensorRT-LLM 适合对性能极致优化的场景。</p><p>推理性能的关键指标包括：吞吐量（tokens/秒）、延迟（首 token 延迟、每 token 延迟）、显存占用（权重 + KV Cache）、并发能力（最大并发请求数）。benchmark 时需要综合考虑这些指标，而非只看吞吐量。</p><h2 id="训练引擎" tabindex="-1">训练引擎 <a class="header-anchor" href="#训练引擎" aria-label="Permalink to “训练引擎”">​</a></h2><p>训练引擎关注如何高效地将大模型训练过程分布式化到多张 GPU 甚至多台机器上。相比于单卡训练，分布式训练引入了通信开销、显存压力、负载均衡等复杂问题，需要在算法、系统和工程三个层面进行协同优化。</p><table tabindex="0"><thead><tr><th>框架</th><th>核心能力</th><th>适用场景</th></tr></thead><tbody><tr><td>DeepSpeed</td><td>ZeRO 显存优化、CPU 卸载</td><td>大规模预训练、显存受限环境</td></tr><tr><td>FSDP</td><td>PyTorch 原生分片训练</td><td>与 PyTorch 生态深度集成</td></tr><tr><td>Megatron-LM</td><td>张量并行、3D 并行</td><td>超大规模模型（100B+）</td></tr><tr><td>Colossal-AI</td><td>Gemini 显存管理、序列并行</td><td>长序列模型、多样化并行策略</td></tr><tr><td>Ray Train</td><td>弹性训练、容错恢复</td><td>云原生环境、故障容忍场景</td></tr></tbody></table><p>选择框架需要考虑团队技术栈、模型规模、硬件拓扑。DeepSpeed 易上手且文档丰富，适合快速实验；FSDP 与 PyTorch 无缝集成，适合已有 PyTorch 代码迁移；Megatron-LM 性能最强但工程复杂度高，适合训练千亿级以上参数模型。</p><h3 id="核心挑战-1" tabindex="-1">核心挑战 <a class="header-anchor" href="#核心挑战-1" aria-label="Permalink to “核心挑战”">​</a></h3><p>大模型训练面临三大核心挑战：<strong>显存容量</strong>、<strong>计算效率</strong>和<strong>通信带宽</strong>。</p>',13)),t("p",null,[e[8]||(e[8]=T("显存容量是首要瓶颈。一个 7B 参数的模型，仅权重就需要约 14GB 显存（FP16），加上激活值、梯度、优化器状态，实际需求可能达到 60GB 以上，远超单卡容量。这催生了 ZeRO、FSDP 等显存优化技术，通过分片存储优化器状态、梯度和参数，将显存占用从 ",-1)),t("mjx-container",i,[(a(),l("svg",d,[...e[4]||(e[4]=[Q('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1152,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1652,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),e[5]||(e[5]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"O"),t("mo",{stretchy:"false"},"("),t("mn",null,"2"),t("mo",{stretchy:"false"},")")])],-1))]),e[9]||(e[9]=T(" 降至 ",-1)),t("mjx-container",m,[(a(),l("svg",p,[...e[6]||(e[6]=[Q('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D442" d="M740 435Q740 320 676 213T511 42T304 -22Q207 -22 138 35T51 201Q50 209 50 244Q50 346 98 438T227 601Q351 704 476 704Q514 704 524 703Q621 689 680 617T740 435ZM637 476Q637 565 591 615T476 665Q396 665 322 605Q242 542 200 428T157 216Q157 126 200 73T314 19Q404 19 485 98T608 313Q637 408 637 476Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(763,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(1152,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1652,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),e[7]||(e[7]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"O"),t("mo",{stretchy:"false"},"("),t("mn",null,"1"),t("mo",{stretchy:"false"},")")])],-1))]),e[10]||(e[10]=T("。",-1))]),e[30]||(e[30]=t("p",null,"计算效率方面，大模型训练的浮点运算量巨大，GPT-3 175B 的训练需要约 3.14 × 10^23 FLOPs。单纯增加 GPU 数量会面临 Amdahl 定律的通信瓶颈，因此需要算子融合（如 FlashAttention）、混合精度训练（BF16/FP16）、编译优化（torch.compile）等技术提升单卡计算效率。",-1)),e[31]||(e[31]=t("p",null,"通信带宽是分布式训练的阿喀琉斯之踵。数据并行需要在每次迭代后同步梯度，模型并行则需要在前向/反向传播中频繁通信张量。NVLink 带宽约 400GB/s，而 PCIe 5.0 仅 32GB/s，跨节点 InfiniBand 通常低于 100GB/s。DeepSpeed、Megatron 通过通信与计算重叠（overlap）、梯度压缩、拓扑感知通信等手段缓解这一问题。",-1)),e[32]||(e[32]=t("h3",{id:"分布式策略",tabindex:"-1"},[T("分布式策略 "),t("a",{class:"header-anchor",href:"#分布式策略","aria-label":"Permalink to “分布式策略”"},"​")],-1)),e[33]||(e[33]=t("p",null,"从数据并行的朴素同步 SGD，到 3D 并行的复杂张量切分，不同策略在通信频率、显存占用、工程复杂度上各有取舍。",-1)),t("p",null,[e[15]||(e[15]=T("数据并行是最直观的方案：每个 GPU 持有完整模型副本，处理不同数据分片，通过 AllReduce 同步梯度。PyTorch DDP 封装了这一模式，但在大模型场景下，多副本的显存开销无法接受。ZeRO 进一步优化了数据并行，将优化器状态、梯度、参数分片到不同 GPU，仅在需要时通过 AllGather 重建，将显存占用从 ",-1)),t("mjx-container",h,[(a(),l("svg",x,[...e[11]||(e[11]=[Q('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mn"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(500,0)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g></g>',1)])])),e[12]||(e[12]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mn",null,"2"),t("mi",null,"n")])],-1))]),e[16]||(e[16]=T(" 倍降至 1 倍（",-1)),t("mjx-container",g,[(a(),l("svg",u,[...e[13]||(e[13]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D45B",d:"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z",style:{"stroke-width":"3"}})])])],-1)])])),e[14]||(e[14]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"n")])],-1))]),e[17]||(e[17]=T(" 为 GPU 数量）。",-1))]),t("p",null,[e[24]||(e[24]=T("张量并行将模型的单个算子在多个 GPU 上切分。例如矩阵乘法 ",-1)),t("mjx-container",w,[(a(),l("svg",c,[...e[18]||(e[18]=[Q('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(1040.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2096.6,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2948.6,0)"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z" style="stroke-width:3;"></path></g></g></g>',1)])])),e[19]||(e[19]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"Y"),t("mo",null,"="),t("mi",null,"X"),t("mi",null,"W")])],-1))]),e[25]||(e[25]=T("，可将权重 ",-1)),t("mjx-container",f,[(a(),l("svg",L,[...e[20]||(e[20]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D44A",d:"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z",style:{"stroke-width":"3"}})])])],-1)])])),e[21]||(e[21]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"W")])],-1))]),e[26]||(e[26]=T(" 按列切分到 4 张卡，每张卡计算 ",-1)),t("mjx-container",b,[(a(),l("svg",k,[...e[22]||(e[22]=[Q('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D44C" d="M66 637Q54 637 49 637T39 638T32 641T30 647T33 664T42 682Q44 683 56 683Q104 680 165 680Q288 680 306 683H316Q322 677 322 674T320 656Q316 643 310 637H298Q242 637 242 624Q242 619 292 477T343 333L346 336Q350 340 358 349T379 373T411 410T454 461Q546 568 561 587T577 618Q577 634 545 637Q528 637 528 647Q528 649 530 661Q533 676 535 679T549 683Q551 683 578 682T657 680Q684 680 713 681T746 682Q763 682 763 673Q763 669 760 657T755 643Q753 637 734 637Q662 632 617 587Q608 578 477 424L348 273L322 169Q295 62 295 57Q295 46 363 46Q379 46 384 45T390 35Q390 33 388 23Q384 6 382 4T366 1Q361 1 324 1T232 2Q170 2 138 2T102 1Q84 1 84 9Q84 14 87 24Q88 27 89 30T90 35T91 39T93 42T96 44T101 45T107 45T116 46T129 46Q168 47 180 50T198 63Q201 68 227 171L252 274L129 623Q128 624 127 625T125 627T122 629T118 631T113 633T105 634T96 635T83 636T66 637Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(614,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g><g data-mml-node="mo" transform="translate(1185.7,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2241.5,0)"><path data-c="1D44B" d="M42 0H40Q26 0 26 11Q26 15 29 27Q33 41 36 43T55 46Q141 49 190 98Q200 108 306 224T411 342Q302 620 297 625Q288 636 234 637H206Q200 643 200 645T202 664Q206 677 212 683H226Q260 681 347 681Q380 681 408 681T453 682T473 682Q490 682 490 671Q490 670 488 658Q484 643 481 640T465 637Q434 634 411 620L488 426L541 485Q646 598 646 610Q646 628 622 635Q617 635 609 637Q594 637 594 648Q594 650 596 664Q600 677 606 683H618Q619 683 643 683T697 681T738 680Q828 680 837 683H845Q852 676 852 672Q850 647 840 637H824Q790 636 763 628T722 611T698 593L687 584Q687 585 592 480L505 384Q505 383 536 304T601 142T638 56Q648 47 699 46Q734 46 734 37Q734 35 732 23Q728 7 725 4T711 1Q708 1 678 1T589 2Q528 2 496 2T461 1Q444 1 444 10Q444 11 446 25Q448 35 450 39T455 44T464 46T480 47T506 54Q523 62 523 64Q522 64 476 181L429 299Q241 95 236 84Q232 76 232 72Q232 53 261 47Q262 47 267 47T273 46Q276 46 277 46T280 45T283 42T284 35Q284 26 282 19Q279 6 276 4T261 1Q258 1 243 1T201 2T142 2Q64 2 42 0Z" style="stroke-width:3;"></path></g><g data-mml-node="msub" transform="translate(3093.5,0)"><g data-mml-node="mi"><path data-c="1D44A" d="M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(977,-150) scale(0.707)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g></g></g></g>',1)])])),e[23]||(e[23]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"Y"),t("mi",null,"i")]),t("mo",null,"="),t("mi",null,"X"),t("msub",null,[t("mi",null,"W"),t("mi",null,"i")])])],-1))]),e[27]||(e[27]=T("，最后通过 AllConcat 拼接结果。这种方式无需复制模型，但每个算子完成后都需要通信，延迟敏感。Megatron-LM 首创了这一技术，用于训练 GPT-3 175B。",-1))]),e[34]||(e[34]=t("p",null,"流水线并行将模型的不同层分配到不同 GPU，形成流水线。GPU 1 计算第 1-12 层，GPU 2 计算 13-24 层，两者可并行处理不同样本。但流水线存在气泡（bubble）空转，需要通过微批次（micro-batch）调度和 1F1B 策略填充。PipeDream、PipeDream-2BW 是早期探索者。",-1)),e[35]||(e[35]=t("p",null,"3D 并行是上述三者的组合：在同一集群内同时使用数据、张量、流水线并行。通常在节点内使用张量并行（高带宽 NVLink），节点间使用流水线并行（跨节点通信少），最外层使用数据并行。Megatron-DeepSpeed 成功用此策略在 3072 张 A100 上训练了 1T 参数的模型。",-1))])}const A=o(n,[["render",v]]);export{C as __pageData,A as default};
