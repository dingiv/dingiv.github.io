import{_ as i,o as a,c as t,ah as h}from"./chunks/framework.BvDvRtye.js";const g=JSON.parse('{"title":"SIMD","description":"","frontmatter":{"title":"SIMD","order":50},"headers":[],"relativePath":"ai/compute/api/cpu.md","filePath":"ai/compute/api/cpu.md"}'),n={name:"ai/compute/api/cpu.md"};function k(l,s,p,e,d,E){return a(),t("div",null,[...s[0]||(s[0]=[h(`<h1 id="simd" tabindex="-1">SIMD <a class="header-anchor" href="#simd" aria-label="Permalink to “SIMD”">​</a></h1><p>SIMD（Single Instruction Multiple Data）是 CPU 实现数据级并行的核心技术。与 GPU 的粗粒度并行（数千个线程同时执行）不同，SIMD 在单个指令周期内同时处理多个数据元素，通过向量化操作提升计算密集型任务的性能。虽然 GPU 在深度学习训练中占据主导地位，但 CPU 的 SIMD 能力在推理场景中仍然不可忽视。</p><h2 id="x86-simd-指令集演进" tabindex="-1">x86 SIMD 指令集演进 <a class="header-anchor" href="#x86-simd-指令集演进" aria-label="Permalink to “x86 SIMD 指令集演进”">​</a></h2><p>x86 架构的 SIMD 指令集经历了多次演进，每次更新都带来更大的寄存器宽度和更丰富的指令集。</p><table tabindex="0"><thead><tr><th>指令集</th><th>年份</th><th>寄存器宽度</th><th>寄存器数</th><th>主要特性</th></tr></thead><tbody><tr><td>MMX</td><td>1996</td><td>64-bit (MM)</td><td>8</td><td>仅整数，与浮点寄存器共享</td></tr><tr><td>SSE</td><td>1999</td><td>128-bit (XMM)</td><td>8</td><td>引入浮点支持</td></tr><tr><td>SSE2</td><td>2001</td><td>128-bit (XMM)</td><td>8</td><td>扩展到 64-bit 系统，增加整数操作</td></tr><tr><td>SSE3</td><td>2004</td><td>128-bit (XMM)</td><td>8</td><td>增加水平操作（hadd、hsub）</td></tr><tr><td>SSE4.1</td><td>2006</td><td>128-bit (XMM)</td><td>8</td><td>增加混合运算、点积指令</td></tr><tr><td>AVX</td><td>2008</td><td>256-bit (YMM)</td><td>16</td><td>寄存器宽度翻倍</td></tr><tr><td>AVX2</td><td>2013</td><td>256-bit (YMM)</td><td>16</td><td>增加整数操作</td></tr><tr><td>AVX-512</td><td>2017</td><td>512-bit (ZMM)</td><td>32</td><td>寄存器宽度再次翻倍</td></tr></tbody></table><p>MMX 是最早的 SIMD 指令集，但设计缺陷导致它很快被 SSE 取代。MMX 的寄存器（MM0-MM7）实际上复用了 x87 浮点寄存器，这意味着在 MMX 代码和浮点代码间切换时需要调用 <code>EMMS</code> 指令清空寄存器状态，带来额外开销。SSE 引入了独立的 XMM 寄存器（XMM0-XMM7），解决了这个问题，并首次引入了浮点 SIMD 操作。</p><p>AVX 将寄存器宽度从 128 位扩展到 256 位，使得一条指令可以处理 8 个 float（32-bit）或 4 个 double（64-bit）。AVX2 进一步增加了整数 SIMD 操作，使得整数和浮点都可用向量指令处理。AVX-512 将寄存器宽度扩展到 512 位，但由于功耗和发热问题，Intel 在后续产品中逐步缩减 AVX-512 支持（如 Alder Lake 只在特定 SKU 上启用）。</p><h2 id="arm-simd-指令集" tabindex="-1">ARM SIMD 指令集 <a class="header-anchor" href="#arm-simd-指令集" aria-label="Permalink to “ARM SIMD 指令集”">​</a></h2><p>ARM 架构的 SIMD 指令集称为 <strong>NEON</strong>，128 位寄存器，支持整数和浮点运算。NEON 在移动设备和 Apple Silicon 芯片中广泛使用，是移动端图像处理、音频编解码的核心加速技术。</p><div class="language-asm"><button title="Copy Code" class="copy"></button><span class="lang">asm</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">// ARM NEON 示例：两个向量相加</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vld1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {q0}, [r0]    @ 加载 </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 个 float 到 q0</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vld1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {q1}, [r1]    @ 加载 </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 个 float 到 q1</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vadd.f32 q0, q0, q1   @ q0 = q0 + q1（</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> 个 float 并行相加）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">vst1</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">.</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">32</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {q0}, [r2]    @ 存储结果</span></span></code></pre></div><p>Apple M 系列芯片的 ARM 架构配合 <strong>AMX（Apple Matrix Multiply）</strong> 协处理器，在矩阵乘法上性能可达传统 CPU 的数倍。AMX 是 Apple 专有的矩阵加速单元，支持 8×8 或 16×16 矩阵乘法，主要用于神经网络的加速。PyTorch 的 MPS 后端会优先使用 AMX 进行矩阵运算。</p><h2 id="simd-编程" tabindex="-1">SIMD 编程 <a class="header-anchor" href="#simd-编程" aria-label="Permalink to “SIMD 编程”">​</a></h2><p>SIMD 编程的核心思想是<strong>向量化</strong>：将标量运算转换为向量运算。例如，计算两个数组的元素和，标量代码需要循环逐个处理，而 SIMD 代码可一次处理 8 个 float（AVX2 的 256 位寄存器可容纳 8 个 32-bit float）。</p><div class="language-c"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 标量代码</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">void</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> add_scalar</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> n</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n; i</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">++</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// SIMD 代码（使用 AVX2 intrinsics）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">#include</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &lt;immintrin.h&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">void</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> add_simd</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> n</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">;</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    // 每次处理 8 个 float（256 位 / 32 位 = 8）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (; i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 8</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> &lt;=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n; i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        __m256 a </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _mm256_loadu_ps</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i);</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">  // 加载 8 个 float</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        __m256 b </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _mm256_loadu_ps</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i);</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        __m256 c </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> _mm256_add_ps</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(a, b);</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">     // 向量加法</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">        _mm256_storeu_ps</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i, c);</span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">         // 存储 8 个 float</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    // 处理剩余元素</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (; i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n; i</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">++</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>编译器可通过自动向量化（auto-vectorization）将简单循环转换为 SIMD 指令，无需手动编写 intrinsics。GCC 的 <code>-O3 -ftree-vectorize</code>、Clang 的 <code>-O3 -Rpass=loop-vectorize</code> 会启用自动向量化。但自动向量化对循环模式有严格要求：循环体内不能有函数调用、分支依赖、复杂的内存访问模式，否则编译器会放弃向量化。</p><div class="language-c"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 可自动向量化</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n; i</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">++</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">// 难以自动向量化（有分支依赖）</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n; i</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">++</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    if</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    } </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">else</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> -</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>对于复杂模式，仍需使用 intrinsics 手动编写 SIMD 代码。主流编译器（GCC、Clang、MSVC）都支持 <code>immintrin.h</code> 头文件，提供了 MMX、SSE、AVX、AVX-512 的 intrinsics。</p><h2 id="多线程并行" tabindex="-1">多线程并行 <a class="header-anchor" href="#多线程并行" aria-label="Permalink to “多线程并行”">​</a></h2><p>除了 SIMD，CPU 还可通过多线程并行实现任务级并行。<strong>OpenMP</strong> 是最常用的并行编程框架，通过 <code>#pragma omp parallel for</code> 编译制导指令，将循环分配到多个线程执行。</p><div class="language-c"><button title="Copy Code" class="copy"></button><span class="lang">c</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">#include</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;"> &lt;omp.h&gt;</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">void</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> add_parallel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">float*</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> n</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    #pragma</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> omp</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> parallel</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> for</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    for</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">int</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> 0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">; i </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n; i</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">++</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">) {</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">        z</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> x</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i] </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;"> y</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[i];</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    }</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}</span></span></code></pre></div><p>OpenMP 会根据 CPU 核心数自动创建线程池，并将循环迭代分配给不同线程。对于 NUMA 架构的多路服务器，还需要考虑 NUMA 亲和性，将线程绑定到特定 CPU 核心，减少跨 socket 的内存访问延迟。Linux 的 <code>numactl</code> 命令或 <code>pthread_setaffinity_np</code> 函数可用于绑定线程到 CPU 核心。</p><p>SIMD 和多线程可以结合使用，实现两级并行：线程级并行（多核）+ 数据级并行（SIMD）。这种组合在现代 CPU 上可获得接近理论峰值的性能。</p><h2 id="blas-和线性代数库" tabindex="-1">BLAS 和线性代数库 <a class="header-anchor" href="#blas-和线性代数库" aria-label="Permalink to “BLAS 和线性代数库”">​</a></h2><p>BLAS（Basic Linear Algebra Subprograms）是线性代数的标准 API，定义了向量运算（Level 1）、矩阵-向量运算（Level 2）、矩阵-矩阵运算（Level 3）的接口。各大厂商提供了优化的 BLAS 实现：</p><table tabindex="0"><thead><tr><th>库</th><th>平台</th><th>特点</th></tr></thead><tbody><tr><td>Intel MKL</td><td>Intel CPU</td><td>优化最深，支持 AVX-512</td></tr><tr><td>OpenBLAS</td><td>开源，跨平台</td><td>性能接近 MKL</td></tr><tr><td>Apple Accelerate</td><td>Apple Silicon</td><td>针对 AMX 优化</td></tr><tr><td>BLIS</td><td>开源，跨平台</td><td>模块化设计，易于移植</td></tr></tbody></table><p>这些库使用 SIMD 指令和汇编优化，矩阵乘法性能可达手写代码的数十倍。PyTorch 的 CPU 后端默认使用 Intel MKL，在 AVX-512 支持的 CPU 上，FP32 矩阵乘法性能可达 500 GFLOPS，约为 A100 GPU（20 TFLOPS）的 2.5%，对于小模型推理已足够。</p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 使用 CPU 后端进行矩阵乘法</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.randn(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1024</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">z </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.mm(x, y)  </span><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 调用 MKL 的 sgemm</span></span></code></pre></div><h2 id="集成显卡加速" tabindex="-1">集成显卡加速 <a class="header-anchor" href="#集成显卡加速" aria-label="Permalink to “集成显卡加速”">​</a></h2><p>集成显卡是与 CPU 共享内存和封装的 GPU，虽然性能远不如独立显卡，但在推理场景中仍可提供显著加速。Intel 的集成显卡支持 OpenCL 和 oneAPI（DPC++/SYCL），可通过 GPU 分享系统内存无需数据传输，延迟远低于独立显卡的 PCIe 传输。</p><p>Apple M 系列芯片的 GPU 核心通过统一内存架构与 CPU 共享内存，Metal Performance Shaders（MPS）提供了类似 CUDA 的计算 API，PyTorch 的 MPS 后端可直接调用。在 M1 Max 上，ResNet-50 推理性能约为 800 FPS（图像尺寸 224×224），约为 CPU（Intel MKL）的 10 倍。</p><p>集成显卡的优势在于功耗和成本。对于边缘设备（如摄像头、机器人），使用集成显卡进行推理无需额外的独立显卡，可降低功耗和硬件成本。Intel 的 OpenVINO 工具包专门优化了集成显卡上的推理性能，支持模型量化（INT8）和算子融合，在 Intel Iris Xe 集成显卡上，ResNet-50 推理性能可达 500 FPS。</p>`,31)])])}const y=i(n,[["render",k]]);export{g as __pageData,y as default};
