import{_ as s,c as l,o as e,j as t,ae as a,a as T}from"./chunks/framework.CDjunVez.js";const n="/assets/dtree.DzHTwOa3.png",o="/assets/perceptron.pF7zEYwi.webp",_=JSON.parse('{"title":"监督学习","description":"","frontmatter":{},"headers":[],"relativePath":"ai/neural/ml/supervised.md","filePath":"ai/neural/ml/supervised.md"}'),r={name:"ai/neural/ml/supervised.md"},d={tabindex:"0"},m={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},i={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.048ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.705ex",height:"1.934ex",role:"img",focusable:"false",viewBox:"0 -833.9 1195.6 854.9","aria-hidden":"true"},p={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},h={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.464ex"},xmlns:"http://www.w3.org/2000/svg",width:"33.799ex",height:"2.034ex",role:"img",focusable:"false",viewBox:"0 -694 14939.1 899","aria-hidden":"true"},g={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.912ex"},xmlns:"http://www.w3.org/2000/svg",width:"32.223ex",height:"2.869ex",role:"img",focusable:"false",viewBox:"0 -864.9 14242.6 1267.9","aria-hidden":"true"},H={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},w={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"7.047ex",height:"1.946ex",role:"img",focusable:"false",viewBox:"0 -666 3114.6 860","aria-hidden":"true"},x={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},f={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.628ex"},xmlns:"http://www.w3.org/2000/svg",width:"23.455ex",height:"2.851ex",role:"img",focusable:"false",viewBox:"0 -982.5 10367.1 1260","aria-hidden":"true"},L={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},y={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-1.236ex"},xmlns:"http://www.w3.org/2000/svg",width:"3.92ex",height:"3.193ex",role:"img",focusable:"false",viewBox:"0 -864.9 1732.6 1411.3","aria-hidden":"true"},V={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},M={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.666ex"},xmlns:"http://www.w3.org/2000/svg",width:"30.619ex",height:"2.552ex",role:"img",focusable:"false",viewBox:"0 -833.9 13533.8 1128.2","aria-hidden":"true"},k={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},Z={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.186ex"},xmlns:"http://www.w3.org/2000/svg",width:"12.433ex",height:"1.756ex",role:"img",focusable:"false",viewBox:"0 -694 5495.4 776","aria-hidden":"true"},b={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"18.687ex",height:"2.398ex",role:"img",focusable:"false",viewBox:"0 -810 8259.4 1060","aria-hidden":"true"};function v(D,Q,C,S,j,A){return e(),l("div",null,[Q[58]||(Q[58]=t("h1",{id:"监督学习",tabindex:"-1"},[T("监督学习 "),t("a",{class:"header-anchor",href:"#监督学习","aria-label":'Permalink to "监督学习"'},"​")],-1)),Q[59]||(Q[59]=t("p",null,"训练数据带有标签，目标是学习特征 → 标签的映射。监督学习主要包括分类和回归两种子类。",-1)),Q[60]||(Q[60]=t("p",null,'回归使用函数来拟合因变量和自变量之间的关系，适合于标签是连续的数值；而有些标签并不是连续数值，例如，判断一个零件质量是否合格，该标签是一个典型的二值枚举，仅包含 "是" 和 "否" 两种结果，此外，还有多分类（如图像识别）。',-1)),t("table",d,[Q[8]||(Q[8]=t("thead",null,[t("tr",null,[t("th",null,"项目"),t("th",null,"分类（Classification）"),t("th",null,"回归（Regression）")])],-1)),t("tbody",null,[Q[5]||(Q[5]=t("tr",null,[t("td",null,"输出类型"),t("td",null,"离散类别（如“是/否”、1/2/3）"),t("td",null,"连续数值（如100.5、-3.2）")],-1)),Q[6]||(Q[6]=t("tr",null,[t("td",null,"决策边界"),t("td",null,"分割类别边界"),t("td",null,"拟合连续曲线/曲面")],-1)),Q[7]||(Q[7]=t("tr",null,[t("td",null,"典型问题"),t("td",null,"邮件分类、疾病诊断、图像识别"),t("td",null,"房价预测、销量预测、温度预测")],-1)),t("tr",null,[Q[3]||(Q[3]=t("td",null,"评估指标",-1)),Q[4]||(Q[4]=t("td",null,"准确率、精确率、召回率、F1、AUC",-1)),t("td",null,[Q[2]||(Q[2]=T("MSE、RMSE、MAE、",-1)),t("mjx-container",m,[(e(),l("svg",i,[...Q[0]||(Q[0]=[a("",1)])])),Q[1]||(Q[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msup",null,[t("mi",null,"R"),t("mn",null,"2")])])],-1))])])])])]),Q[61]||(Q[61]=t("p",null,[T("不同的算法实现方式不同，但是有相同的核心任务，那就是在训练数据上学习一个函数 f，使得在新数据上预测尽可能准确（泛化能力强）。这些算法中，有一些从一开始便已经判断出数据之间具有的函数关系的形式，只是函数中的某些位置的上的参数不确定，典型的如线性回归，在一开始，我们便已经确定了某个参数就是类似于线性关系的模式，不确定的是这个线性函数中的 w 和 b 参数。为此，可以将模型分为"),t("strong",null,"有参模型和无参模型"),T("。有参模型往往需要大量的数据统计进行训练，从而拟合出模型的中的可变参数；无参模型，仅需进行少量的训练或者无需训练，即可通过现场归纳数据进行预测。")],-1)),Q[62]||(Q[62]=t("h2",{id:"线性回归",tabindex:"-1"},[T("线性回归 "),t("a",{class:"header-anchor",href:"#线性回归","aria-label":'Permalink to "线性回归"'},"​")],-1)),Q[63]||(Q[63]=t("p",null,"线性回归是最基本的数据分析模型，它假设自变量和因变量之间具有一个简单的函数关系，用直线/超平面拟合变量之间规律。这种方法在高中的课本上就已经教授过。",-1)),t("ul",null,[Q[12]||(Q[12]=t("li",null,"任务：回归。",-1)),t("li",null,[Q[11]||(Q[11]=T("模型：",-1)),t("mjx-container",p,[(e(),l("svg",h,[...Q[9]||(Q[9]=[a("",1)])])),Q[10]||(Q[10]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"y"),t("mo",null,"="),t("msub",null,[t("mi",null,"w"),t("mn",null,"1")]),t("msub",null,[t("mi",null,"x"),t("mn",null,"1")]),t("mo",null,"+"),t("msub",null,[t("mi",null,"w"),t("mn",null,"2")]),t("msub",null,[t("mi",null,"x"),t("mn",null,"2")]),t("mo",null,"+"),t("mo",null,"⋯"),t("mo",null,"+"),t("msub",null,[t("mi",null,"w"),t("mi",null,"n")]),t("msub",null,[t("mi",null,"x"),t("mi",null,"n")]),t("mo",null,"+"),t("mi",null,"b")])],-1))])]),Q[13]||(Q[13]=t("li",null,"损失：均方误差",-1)),Q[14]||(Q[14]=t("li",null,"优缺点：简单、可解释、计算快。线性假设，对异常值敏感。可以通过岭回归（L2正则）、Lasso（L1正则）防过拟合。",-1))]),Q[64]||(Q[64]=t("p",null,[T("线性回归的求解方式主要有两种方式：最小二乘法（闭式）或者"),t("a",{href:"./loss"},"梯度下降法"),T("，其中，最小二乘法是纯数学的实现方式，而梯度下降法是我们软件或计算机行业具体落地的时候的实践方式。")],-1)),Q[65]||(Q[65]=t("h2",{id:"逻辑回归",tabindex:"-1"},[T("逻辑回归 "),t("a",{class:"header-anchor",href:"#逻辑回归","aria-label":'Permalink to "逻辑回归"'},"​")],-1)),Q[66]||(Q[66]=t("p",null,"逻辑回归是一种仿照通过线性回归改造的用于分类的算法，尽管它叫回归。",-1)),t("ul",null,[Q[22]||(Q[22]=t("li",null,[T("任务：分类（常二分类）。基于线性回归 + Sigmoid，将输出转为 "),t("code",null,"[0,1]"),T(" 概率。")],-1)),t("li",null,[Q[19]||(Q[19]=T("模型：",-1)),t("mjx-container",g,[(e(),l("svg",u,[...Q[15]||(Q[15]=[a("",1)])])),Q[16]||(Q[16]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"z"),t("mo",null,"="),t("mi",null,"w"),t("mo",null,"⋅"),t("mi",null,"x"),t("mo",null,"+"),t("mi",null,"b"),t("mo",null,","),t("mstyle",{scriptlevel:"0"},[t("mspace",{width:"1em"})]),t("mi",null,"p"),t("mo",null,"="),t("mi",null,"σ"),t("mo",{stretchy:"false"},"("),t("mi",null,"z"),t("mo",{stretchy:"false"},")"),t("mo",null,"="),t("mfrac",null,[t("mn",null,"1"),t("mrow",null,[t("mn",null,"1"),t("mo",null,"+"),t("msup",null,[t("mi",null,"e"),t("mrow",{"data-mjx-texclass":"ORD"},[t("mo",null,"−"),t("mi",null,"z")])])])])])],-1))]),Q[20]||(Q[20]=T("，预测：",-1)),t("mjx-container",H,[(e(),l("svg",w,[...Q[17]||(Q[17]=[a("",1)])])),Q[18]||(Q[18]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"p"),t("mo",null,"≥"),t("mn",null,"0.5")])],-1))]),Q[21]||(Q[21]=T(" → 正类。",-1))]),Q[23]||(Q[23]=t("li",null,"损失：交叉熵",-1)),Q[24]||(Q[24]=t("li",null,"优缺点：输出概率、可解释、快、适合高维。线性决策边界、多分类需One-vs-Rest。",-1)),Q[25]||(Q[25]=t("li",null,"适用：垃圾邮件、疾病诊断。",-1))]),Q[67]||(Q[67]=t("h2",{id:"knn",tabindex:"-1"},[T("KNN "),t("a",{class:"header-anchor",href:"#knn","aria-label":'Permalink to "KNN"'},"​")],-1)),Q[68]||(Q[68]=t("p",null,"K近邻算法是一种简单、直观且经典的机器学习算法，属于懒惰学习（lazy learning），即训练阶段几乎不做任何计算，只存储数据；预测时才进行计算。",-1)),Q[69]||(Q[69]=t("p",null,"根据测试样本在特征空间中最接近的 K 个训练样本的类别（或值），来预测测试样本的类别（分类）或数值（回归）。该算法体现了一个思想：近朱者赤，近墨者黑。我们会通过观察一个“人”周围的朋友来判断这个“人”的好坏。",-1)),t("ul",null,[Q[30]||(Q[30]=t("li",null,"任务：分类或者回归均可以。分类：少数服从多数（投票）；回归：取 K 个邻居的平均值（或加权平均）；",-1)),t("li",null,[Q[28]||(Q[28]=T("模型：欧氏距离 ",-1)),t("mjx-container",x,[(e(),l("svg",f,[...Q[26]||(Q[26]=[a("",1)])])),Q[27]||(Q[27]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"d"),t("mo",{stretchy:"false"},"("),t("mi",null,"x"),t("mo",null,","),t("mi",null,"y"),t("mo",{stretchy:"false"},")"),t("mo",null,"="),t("msqrt",null,[t("mo",{"data-mjx-texclass":"OP"},"∑"),t("mo",{stretchy:"false"},"("),t("msub",null,[t("mi",null,"x"),t("mi",null,"i")]),t("mo",null,"−"),t("msub",null,[t("mi",null,"y"),t("mi",null,"i")]),t("msup",null,[t("mo",{stretchy:"false"},")"),t("mn",null,"2")])])])],-1))]),Q[29]||(Q[29]=T("。",-1))]),Q[31]||(Q[31]=t("li",null,"超参数：K值（小→过拟合，大→欠拟合，用交叉验证调优）。",-1)),Q[32]||(Q[32]=t("li",null,"优缺点：简单、非线性、对分布无假设。计算慢（O(n)）、存储全数据、高维差、需标准化。",-1)),Q[33]||(Q[33]=t("li",null,"适用：小数据集、基线模型。",-1))]),Q[70]||(Q[70]=a("",6)),t("ul",null,[Q[42]||(Q[42]=t("li",null,"任务：分类/回归。找最大间隔超平面分割类别。",-1)),t("li",null,[Q[36]||(Q[36]=T("硬间隔：线性可分，最大化",-1)),t("mjx-container",L,[(e(),l("svg",y,[...Q[34]||(Q[34]=[a("",1)])])),Q[35]||(Q[35]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mfrac",null,[t("mn",null,"2"),t("mrow",null,[t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("mi",null,"w"),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|")])])])],-1))]),Q[37]||(Q[37]=T("。",-1))]),Q[43]||(Q[43]=t("li",null,"软间隔：引入松弛变量+铰链损失，容忍噪声。",-1)),t("li",null,[Q[40]||(Q[40]=T("核技巧：RBF核",-1)),t("mjx-container",V,[(e(),l("svg",M,[...Q[38]||(Q[38]=[a("",1)])])),Q[39]||(Q[39]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"K"),t("mo",{stretchy:"false"},"("),t("msub",null,[t("mi",null,"x"),t("mi",null,"i")]),t("mo",null,","),t("msub",null,[t("mi",null,"x"),t("mi",null,"j")]),t("mo",{stretchy:"false"},")"),t("mo",null,"="),t("mi",null,"exp"),t("mo",{"data-mjx-texclass":"NONE"},"⁡"),t("mo",{stretchy:"false"},"("),t("mo",null,"−"),t("mi",null,"γ"),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("msub",null,[t("mi",null,"x"),t("mi",null,"i")]),t("mo",null,"−"),t("msub",null,[t("mi",null,"x"),t("mi",null,"j")]),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("msup",null,[t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("mn",null,"2")]),t("mo",{stretchy:"false"},")")])],-1))]),Q[41]||(Q[41]=T(" 处理非线性。",-1))]),Q[44]||(Q[44]=t("li",null,"优点：泛化强、少样本有效、高维好。",-1)),Q[45]||(Q[45]=t("li",null,"缺点：训练慢（O(n^2/n^3)）、参数调优难、不可解释。",-1)),Q[46]||(Q[46]=t("li",null,"适用：文本分类、图像。",-1))]),Q[71]||(Q[71]=t("h2",{id:"感知机",tabindex:"-1"},[T("感知机 "),t("a",{class:"header-anchor",href:"#感知机","aria-label":'Permalink to "感知机"'},"​")],-1)),Q[72]||(Q[72]=t("p",null,"感知机（Perceptron）是机器学习中最古老、最简单的神经网络模型，它是单层神经网络的原型，主要用于二分类任务。感知机试图找到一个线性超平面，将两类样本完全分开（假设数据线性可分）。感知机是现代深度学习的前身。",-1)),Q[73]||(Q[73]=t("p",null,[t("img",{src:o,alt:""})],-1)),t("ul",null,[Q[54]||(Q[54]=t("li",null,"任务：二分类。最简单神经网络，线性分类器。",-1)),t("li",null,[Q[49]||(Q[49]=T("模型：",-1)),t("mjx-container",k,[(e(),l("svg",Z,[...Q[47]||(Q[47]=[a("",1)])])),Q[48]||(Q[48]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"w"),t("mo",null,"⋅"),t("mi",null,"x"),t("mo",null,"+"),t("mi",null,"b"),t("mo",null,">"),t("mn",null,"0")])],-1))]),Q[50]||(Q[50]=T(" → 正类。",-1))]),t("li",null,[Q[53]||(Q[53]=T("更新：误差驱动",-1)),t("mjx-container",b,[(e(),l("svg",c,[...Q[51]||(Q[51]=[a("",1)])])),Q[52]||(Q[52]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"w"),t("mo",{stretchy:"false"},"←"),t("mi",null,"w"),t("mo",null,"+"),t("mi",null,"η"),t("mo",{stretchy:"false"},"("),t("mi",null,"y"),t("mo",null,"−"),t("mrow",{"data-mjx-texclass":"ORD"},[t("mover",null,[t("mi",null,"y"),t("mo",{stretchy:"false"},"^")])]),t("mo",{stretchy:"false"},")"),t("mi",null,"x")])],-1))])]),Q[55]||(Q[55]=t("li",null,"优点：在线学习、简单。",-1)),Q[56]||(Q[56]=t("li",null,"缺点：仅线性可分（XOR问题）、收敛需线性可分数据。",-1)),Q[57]||(Q[57]=t("li",null,"历史：Rosenblatt 1958，奠基神经网络。",-1))]),Q[74]||(Q[74]=a("",5))])}const B=s(r,[["render",v]]);export{_ as __pageData,B as default};
