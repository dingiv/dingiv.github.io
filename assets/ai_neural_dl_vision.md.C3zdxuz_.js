import{_ as i,c as l,o as Q,ae as a,j as t,a as o}from"./chunks/framework.CDjunVez.js";const C=JSON.parse('{"title":"视觉","description":"","frontmatter":{"title":"视觉","order":30},"headers":[],"relativePath":"ai/neural/dl/vision.md","filePath":"ai/neural/dl/vision.md"}'),n={name:"ai/neural/dl/vision.md"},s={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},T={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"1.14ex",height:"1.545ex",role:"img",focusable:"false",viewBox:"0 -683 504 683","aria-hidden":"true"},r={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},d={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"2.011ex",height:"1.545ex",role:"img",focusable:"false",viewBox:"0 -683 889 683","aria-hidden":"true"},m={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},p={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"2.011ex",height:"1.545ex",role:"img",focusable:"false",viewBox:"0 -683 889 683","aria-hidden":"true"},h={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"0"},xmlns:"http://www.w3.org/2000/svg",width:"1.14ex",height:"1.545ex",role:"img",focusable:"false",viewBox:"0 -683 504 683","aria-hidden":"true"},x={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},g={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.268ex",height:"2.034ex",role:"img",focusable:"false",viewBox:"0 -705 1002.6 899","aria-hidden":"true"},w={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},f={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.439ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.595ex",height:"2.034ex",role:"img",focusable:"false",viewBox:"0 -705 1146.8 899","aria-hidden":"true"},c={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},b={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"13.606ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 6014 1000","aria-hidden":"true"};function v(k,e,H,L,N,M){return Q(),l("div",null,[e[24]||(e[24]=a('<h1 id="计算机视觉" tabindex="-1">计算机视觉 <a class="header-anchor" href="#计算机视觉" aria-label="Permalink to &quot;计算机视觉&quot;">​</a></h1><p>计算机视觉旨在让机器能够&quot;看懂&quot;图像和视频，这是人工智能中最接近人类感知的领域。从技术发展史看，视觉领域经历了从手工设计特征（如 SIFT、HOG）到传统机器学习（SVM + 特征），再到深度学习革命的完整演进。2012 年 AlexNet 在 ImageNet 竞赛中的突破性表现标志着 CNN 时代的到来，随后 ResNet、YOLO、Mask R-CNN 等架构不断刷新性能上限。2020 年之后，Vision Transformer（ViT）将自然语言处理中的注意力机制引入视觉领域，证明了纯 Transformer 架构在图像任务上的可行性。最近的扩散模型（Diffusion Model）则在图像生成领域展现出惊人的效果，Midjourney、Stable Diffusion 等产品让 AI 生成图像走进了大众视野。</p><p>计算机视觉的进步极大地扩展了 AI 的应用边界。自动驾驶汽车需要实时理解道路场景，识别行人、车辆、交通标志；医疗影像诊断系统能够辅助医生发现肿瘤、视网膜病变等异常；安防监控通过人脸识别和行为分析提升安全性；工业质检自动检测产品缺陷；内容审核平台识别违规图像；手机相机自动优化拍照效果。这些应用背后都是视觉算法的支撑，而且需求差异巨大——有的要求毫秒级响应（自动驾驶），有的需要极高精度（医疗诊断），有的要处理极端条件（夜间、恶劣天气）。</p><h2 id="视觉任务" tabindex="-1">视觉任务 <a class="header-anchor" href="#视觉任务" aria-label="Permalink to &quot;视觉任务&quot;">​</a></h2><p>计算机视觉任务可以根据输入输出类型划分为几个主要类别。</p><ul><li>图像分类是最基础的任务，输入一张图像，输出属于预定义类别中的哪一类（如猫、狗、飞机、汽车）。ImageNet 竞赛推动了这个领域的发展，从 2012 年 AlexNet 的 15.3% 错误率到后来人类水平的 5% 左右，分类模型的准确率已经超过了人类。实际应用中，图像分类是相册自动归类、商品识别、场景理解等系统的基础。</li><li>目标检测不仅要识别图像中的物体类别，还要定位它们的位置。检测算法输出的通常是边界框（Bounding Box）和类别标签。这个任务的挑战在于图像中可能存在多个物体、物体大小差异大、可能有遮挡。YOLO 系列算法（You Only Look Once）通过单阶段检测实现了实时性能，在工业界应用广泛；Faster R-CNN 等两阶段算法则在精度上更有优势。目标检测是自动驾驶、视频监控、机器人导航的核心技术。</li><li>语义分割为图像中的每个像素分配类别标签，输出是与原图等大的分类图。与目标检测不同，分割不关心&quot;有几个物体&quot;，而是精确到像素级别——哪里是道路、哪里是人行道、哪里是车辆。这个任务对自动驾驶至关重要，车辆需要知道道路的精确边界才能安全行驶。FCN（Fully Convolutional Network）、U-Net 是早期的经典架构，DeepLab 系列引入了空洞卷积来扩大感受野。</li><li>实例分割是更细粒度的任务，不仅要区分类别，还要区分个体。比如图像中有三只猫，语义分割只会标注&quot;猫&quot;，而实例分割会分别标出&quot;猫1&quot;、&quot;猫2&quot;、&quot;猫3&quot;。Mask R-CNN 是这个任务的标杆模型，它在目标检测的基础上增加了分割分支。实例分割在计数场景（如细胞计数、人群统计）和精细编辑（如抠图）中非常重要。</li><li>关键点检测（Keypoint Detection），识别人体姿态、面部特征点。</li></ul><p>AIGC 线路任务</p><ul><li>图像生成（Image Generation），从文本或噪声生成逼真图像；</li><li>风格迁移（Style Transfer），将一张图的风格应用到另一张图；</li><li>图像增强（Image Enhancement），超分辨率、去噪、低光增强；</li><li>视频理解，动作识别、视频分类、时序定位；</li></ul><h2 id="cnn" tabindex="-1">CNN <a class="header-anchor" href="#cnn" aria-label="Permalink to &quot;CNN&quot;">​</a></h2><p>卷积神经网络（Convolutional Neural Network）是计算机视觉领域统治性的架构，从 2012 年到 2020 年，几乎所有视觉突破都基于 CNN。CNN 的核心思想是利用图像的局部相关性和平移不变性——图像中相邻的像素高度相关，某个特征（如边缘）在图像不同位置具有相同的意义。卷积操作通过滑动窗口在图像上提取特征，权值共享大幅减少了参数量，使得处理高维图像成为可能。</p><p>CNN 的发展历程体现了架构设计的演进。LeNet-5（1998）是最早的实用 CNN，包含卷积层、池化层、全连接层的经典结构。AlexNet（2012）通过 ReLU 激活、Dropout 正则化、GPU 并行训练，在 ImageNet 上取得突破。VGG（2014）使用更小的卷积核（3×3）堆叠更深的网络，证明了深度的重要性。GoogLeNet（2014）引入 Inception 模块，多尺度并行处理提升了效率。ResNet（2015）通过残差连接解决了深层网络训练难题，达到了 152 层，成为新的标准架构。</p><h3 id="基本架构" tabindex="-1">基本架构 <a class="header-anchor" href="#基本架构" aria-label="Permalink to &quot;基本架构&quot;">​</a></h3><p>典型的 CNN 包含卷积层、池化层、全连接层三类组件。</p><p>卷积层负责特征提取，通过卷积核在输入上滑动计算点积，每个卷积核学习一种特定的特征模式（如边缘、纹理、形状）。早期的层检测低级特征（边缘、颜色），深层组合低级特征形成高级特征（眼睛、汽车轮廓）。多个卷积核可以并行工作，每个核产生一个特征图（Feature Map），这些特征图堆叠起来形成立体输出。</p><p>池化层（Pooling Layer）进行下采样，降低特征图的空间尺寸。最大池化（Max Pooling）在局部窗口内取最大值，平均池化（Average Pooling）取平均值。池化的作用是减少参数量和计算量，同时引入平移不变性——特征轻微移动不影响池化结果。但过度的池化会丢失位置信息，这在需要精确定位的任务（如分割）中是个问题。现代架构中，池化逐渐被步长卷积（Strided Convolution）取代。</p><p>全连接层（Fully Connected Layer）位于网络末端，将卷积提取的特征映射到输出空间。分类任务中，全连接层输出每个类别的分数，经过 softmax 得到概率分布。但全连接层参数量巨大（例如 7×7×512 的特征展平后有 25088 维），容易过拟合。现代网络用全局平均池化（Global Average Pooling）替代全连接层，直接对每个特征图求平均，大幅减少参数。</p><h3 id="卷积层" tabindex="-1">卷积层 <a class="header-anchor" href="#卷积层" aria-label="Permalink to &quot;卷积层&quot;">​</a></h3>',17)),t("p",null,[e[8]||(e[8]=o("卷积是 CNN 的灵魂操作。给定输入图像 ",-1)),t("mjx-container",s,[(Q(),l("svg",T,[...e[0]||(e[0]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D43C",d:"M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z",style:{"stroke-width":"3"}})])])],-1)])])),e[1]||(e[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"I")])],-1))]),e[9]||(e[9]=o(" 和卷积核 ",-1)),t("mjx-container",r,[(Q(),l("svg",d,[...e[2]||(e[2]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D43E",d:"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z",style:{"stroke-width":"3"}})])])],-1)])])),e[3]||(e[3]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"K")])],-1))]),e[10]||(e[10]=o("，卷积计算的是 ",-1)),t("mjx-container",m,[(Q(),l("svg",p,[...e[4]||(e[4]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D43E",d:"M285 628Q285 635 228 637Q205 637 198 638T191 647Q191 649 193 661Q199 681 203 682Q205 683 214 683H219Q260 681 355 681Q389 681 418 681T463 682T483 682Q500 682 500 674Q500 669 497 660Q496 658 496 654T495 648T493 644T490 641T486 639T479 638T470 637T456 637Q416 636 405 634T387 623L306 305Q307 305 490 449T678 597Q692 611 692 620Q692 635 667 637Q651 637 651 648Q651 650 654 662T659 677Q662 682 676 682Q680 682 711 681T791 680Q814 680 839 681T869 682Q889 682 889 672Q889 650 881 642Q878 637 862 637Q787 632 726 586Q710 576 656 534T556 455L509 418L518 396Q527 374 546 329T581 244Q656 67 661 61Q663 59 666 57Q680 47 717 46H738Q744 38 744 37T741 19Q737 6 731 0H720Q680 3 625 3Q503 3 488 0H478Q472 6 472 9T474 27Q478 40 480 43T491 46H494Q544 46 544 71Q544 75 517 141T485 216L427 354L359 301L291 248L268 155Q245 63 245 58Q245 51 253 49T303 46H334Q340 37 340 35Q340 19 333 5Q328 0 317 0Q314 0 280 1T180 2Q118 2 85 2T49 1Q31 1 31 11Q31 13 34 25Q38 41 42 43T65 46Q92 46 125 49Q139 52 144 61Q147 65 216 339T285 628Z",style:{"stroke-width":"3"}})])])],-1)])])),e[5]||(e[5]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"K")])],-1))]),e[11]||(e[11]=o(" 在 ",-1)),t("mjx-container",h,[(Q(),l("svg",u,[...e[6]||(e[6]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D43C",d:"M43 1Q26 1 26 10Q26 12 29 24Q34 43 39 45Q42 46 54 46H60Q120 46 136 53Q137 53 138 54Q143 56 149 77T198 273Q210 318 216 344Q286 624 286 626Q284 630 284 631Q274 637 213 637H193Q184 643 189 662Q193 677 195 680T209 683H213Q285 681 359 681Q481 681 487 683H497Q504 676 504 672T501 655T494 639Q491 637 471 637Q440 637 407 634Q393 631 388 623Q381 609 337 432Q326 385 315 341Q245 65 245 59Q245 52 255 50T307 46H339Q345 38 345 37T342 19Q338 6 332 0H316Q279 2 179 2Q143 2 113 2T65 2T43 1Z",style:{"stroke-width":"3"}})])])],-1)])])),e[7]||(e[7]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"I")])],-1))]),e[12]||(e[12]=o(" 上每个位置的加权和。卷积核的参数（权重）通过反向传播学习，训练好的卷积核会自动学会提取有用的特征——第一层的卷积核可能学习到边缘检测器，第二层学习到纹理模式，更深层的卷积核组合成复杂的物体部件。",-1))]),e[25]||(e[25]=a('<p>卷积操作有几个关键超参数。卷积核大小（Kernel Size）通常选择奇数（3×3、5×5），这样可以对称地处理中心像素。3×3 卷积是最常用的选择，多个 3×3 卷积堆叠等效于一个大的感受野，但参数更少、非线性更多。步长（Stride）决定卷积核滑动的步幅，步长为 1 逐像素滑动，步长为 2 会跳过一些像素从而降低输出尺寸。填充（Padding）在图像边缘补零，控制输出尺寸是否缩小，Valid padding 不填充导致缩小，Same padding 填充使尺寸保持不变。</p><p>卷积层的设计有多个变种。空洞卷积（Dilated Convolution）在卷积核元素之间插入空洞，扩大感受野而不增加参数量，这在分割任务中很有用。深度可分离卷积（Depthwise Separable Convolution）将标准卷积拆分为深度卷积（每个输入通道单独卷积）和逐点卷积（1×1 卷积混合通道），参数量减少到原来的 1/8 左右，MobileNet 系列基于此实现轻量化。分组卷积（Grouped Convolution）将输入通道分组，每组独立卷积，ResNeXt 用这个技巧提升了性能。</p><h2 id="vit" tabindex="-1">ViT <a class="header-anchor" href="#vit" aria-label="Permalink to &quot;ViT&quot;">​</a></h2><p>Vision Transformer（ViT）是 2020 年 Google 提出的架构，将纯 Transformer 应用于图像任务，打破了 CNN 的垄断。ViT 的核心思想是将图像分割成固定大小的图块（Patch），每个图块视为一个&quot;词&quot;，线性投影后得到序列向量，然后输入标准的 Transformer 编码器。这个设计极其简洁——没有卷积、没有池化、没有 CNN 特有的归纳偏置，纯粹靠注意力机制和大规模预训练学习视觉表示。</p><p>ViT 的成功依赖于大规模数据和预训练。原始 ViT 在 ImageNet-1K（120 万张图）上训练时，效果不如同等规模的 ResNet；但在 ImageNet-21K（1400 万张图）或 JFT-300M（3 亿张图）上预训练后，ViT 显著超越了 CNN。这说明 Transformer 的架构没有 CNN 那样强的先验假设（如局部性、平移不变性），需要更多数据来学习这些特性。一旦训练充分，Transformer 的全局注意力机制展现出 CNN 无法比拟的优势——每个图块都能直接与其他所有图块交互，不受感受野限制。</p><p>ViT 的架构细节体现了从 NLP 借鉴的设计智慧。图像分割成 16×16 的图块（对于 224×224 的图像，得到 196 个图块），每个图块展平成向量后通过线性投影得到嵌入向量。位置编码是必须的，因为 Transformer 本身不包含位置信息，ViT 使用可学习的位置嵌入，随机初始化后随训练更新。分类头采用 [CLS] token 的方式，类似 BERT，在序列前增加一个可学习的分类标记，最终输出这个标记的表示用于分类。</p><p>Swin Transformer 是 ViT 的重要改进版本，引入了层次化和局部注意力。标准 ViT 的全局注意力计算量随图像尺寸平方增长，难以处理高分辨率图像。Swin Transformer 基于 shifted window attention，在局部窗口内计算注意力，同时通过窗口移动实现跨窗口连接。这种设计使得 Swin Transformer 既可以作为通用骨干网络（Backbone）用于检测、分割，又保持了 Transformer 的全局建模能力。</p><p>ViT 与 CNN 的对比是视觉领域的重要话题。CNN 的优势在于归纳偏置强、数据效率高、训练稳定，适合中小规模数据；ViT 的优势在于全局建模能力强、可扩展性好，在大规模数据上表现更优。实际应用中，选择 CNN 还是 ViT 取决于数据规模、计算资源、任务特性。目前的研究趋势是融合两者优点，如 ConvNeXt 将卷积网络改造成 Transformer 风格的训练范式，CoAtNet 结合卷积和注意力。</p><h2 id="diffusion" tabindex="-1">Diffusion <a class="header-anchor" href="#diffusion" aria-label="Permalink to &quot;Diffusion&quot;">​</a></h2><p>扩散模型（Diffusion Model）是近年来图像生成领域最具突破性的技术，其生成的图像质量、多样性远超之前的 GAN 和 VAE。Diffusion 背后的思想受启发于热力学中的扩散现象——如果向清水中滴入墨水，墨水会逐渐扩散直至均匀分布。逆过程则是从均匀噪声中逐步&quot;去噪&quot;恢复出清晰图像。这个思路在 2015 年就被提出，但直到 2020 年 DDPM（Denoising Diffusion Probabilistic Models）才在图像生成上取得显著效果。</p><p>扩散模型的训练过程是逐步向图像添加噪声，直到变成纯高斯噪声。具体来说，给定一张图像，我们多次添加小幅高斯噪声，每一步的噪声量由噪声调度表（Noise Schedule）控制。训练神经网络预测每一步添加的噪声，网络输入是当前带噪图像，输出是预测的噪声。训练目标是最小化预测噪声与真实噪声的差异，这个过程可以通过简单的均方误差损失来优化。</p><p>生成过程是训练的逆过程——从随机噪声开始，逐步去噪直到得到清晰图像。每一步用训练好的模型预测噪声，然后从当前图像中减去预测的噪声，得到稍清晰的图像。重复这个过程数百到数千步，最终得到生成结果。这个生成过程是迭代的，比 GAN 的一次前向传播慢得多，但生成的图像质量显著更高，训练也更稳定（不会出现模式崩溃）。</p>',12)),t("p",null,[e[17]||(e[17]=o("扩散模型的核心设计选择包括噪声调度表、网络架构、采样策略。噪声调度表决定每步添加的噪声量，线性调度从 ",-1)),t("mjx-container",x,[(Q(),l("svg",g,[...e[13]||(e[13]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g><g data-mml-node="mn" transform="translate(599,-150) scale(0.707)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" style="stroke-width:3;"></path></g></g></g></g>',1)])])),e[14]||(e[14]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"β"),t("mn",null,"1")])])],-1))]),e[18]||(e[18]=o(" 线性增长到 ",-1)),t("mjx-container",w,[(Q(),l("svg",f,[...e[15]||(e[15]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(599,-150) scale(0.707)"><path data-c="1D447" d="M40 437Q21 437 21 445Q21 450 37 501T71 602L88 651Q93 669 101 677H569H659Q691 677 697 676T704 667Q704 661 687 553T668 444Q668 437 649 437Q640 437 637 437T631 442L629 445Q629 451 635 490T641 551Q641 586 628 604T573 629Q568 630 515 631Q469 631 457 630T439 622Q438 621 368 343T298 60Q298 48 386 46Q418 46 427 45T436 36Q436 31 433 22Q429 4 424 1L422 0Q419 0 415 0Q410 0 363 1T228 2Q99 2 64 0H49Q43 6 43 9T45 27Q49 40 55 46H83H94Q174 46 189 55Q190 56 191 56Q196 59 201 76T241 233Q258 301 269 344Q339 619 339 625Q339 630 310 630H279Q212 630 191 624Q146 614 121 583T67 467Q60 445 57 441T43 437H40Z" style="stroke-width:3;"></path></g></g></g></g>',1)])])),e[16]||(e[16]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"β"),t("mi",null,"T")])])],-1))]),e[19]||(e[19]=o("，余弦调度则在开始和结束时变化更平缓。网络架构通常使用 U-Net，具有编码器-解码器结构和跳跃连接，能够同时捕捉多尺度特征。采样策略方面，DDPM 使用数百到数千步的马尔可夫链蒙特卡洛采样，DDIM（Denoising Diffusion Implicit Models）通过非马尔可夫过程将采样步数减少到 50 步甚至更少。",-1))]),e[26]||(e[26]=t("p",null,"Latent Diffusion 是扩散模型的重要改进，在潜在空间而非像素空间进行扩散。直接在像素空间操作的计算量巨大，图像分辨率稍有增加就会导致显存爆炸。Latent Diffusion 先用编码器将图像压缩到低维潜在空间（压缩比通常为 4-8 倍），在潜在空间训练扩散模型，生成时再用解码器恢复到像素空间。Stable Diffusion 就是基于 Latent Diffusion，它能在消费级 GPU 上生成高分辨率图像，是扩散模型普及的关键。",-1)),t("p",null,[e[22]||(e[22]=o("扩散模型的应用已经超越图像生成。文本到图像（Text-to-Image）生成中，模型学习条件概率 ",-1)),t("mjx-container",c,[(Q(),l("svg",b,[...e[20]||(e[20]=[a('<g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D45D" d="M23 287Q24 290 25 295T30 317T40 348T55 381T75 411T101 433T134 442Q209 442 230 378L240 387Q302 442 358 442Q423 442 460 395T497 281Q497 173 421 82T249 -10Q227 -10 210 -4Q199 1 187 11T168 28L161 36Q160 35 139 -51T118 -138Q118 -144 126 -145T163 -148H188Q194 -155 194 -157T191 -175Q188 -187 185 -190T172 -194Q170 -194 161 -194T127 -193T65 -192Q-5 -192 -24 -194H-32Q-39 -187 -39 -183Q-37 -156 -26 -148H-6Q28 -147 33 -136Q36 -130 94 103T155 350Q156 355 156 364Q156 405 131 405Q109 405 94 377T71 316T59 280Q57 278 43 278H29Q23 284 23 287ZM178 102Q200 26 252 26Q282 26 310 49T356 107Q374 141 392 215T411 325V331Q411 405 350 405Q339 405 328 402T306 393T286 380T269 365T254 350T243 336T235 326L232 322Q232 321 229 308T218 264T204 212Q178 106 178 102Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(503,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(892,0)"><path data-c="1D456" d="M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(1237,0)"><path data-c="1D45A" d="M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2115,0)"><path data-c="1D44E" d="M33 157Q33 258 109 349T280 441Q331 441 370 392Q386 422 416 422Q429 422 439 414T449 394Q449 381 412 234T374 68Q374 43 381 35T402 26Q411 27 422 35Q443 55 463 131Q469 151 473 152Q475 153 483 153H487Q506 153 506 144Q506 138 501 117T481 63T449 13Q436 0 417 -8Q409 -10 393 -10Q359 -10 336 5T306 36L300 51Q299 52 296 50Q294 48 292 46Q233 -10 172 -10Q117 -10 75 30T33 157ZM351 328Q351 334 346 350T323 385T277 405Q242 405 210 374T160 293Q131 214 119 129Q119 126 119 118T118 106Q118 61 136 44T179 26Q217 26 254 59T298 110Q300 114 325 217T351 328Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(2644,0)"><path data-c="1D454" d="M311 43Q296 30 267 15T206 0Q143 0 105 45T66 160Q66 265 143 353T314 442Q361 442 401 394L404 398Q406 401 409 404T418 412T431 419T447 422Q461 422 470 413T480 394Q480 379 423 152T363 -80Q345 -134 286 -169T151 -205Q10 -205 10 -137Q10 -111 28 -91T74 -71Q89 -71 102 -80T116 -111Q116 -121 114 -130T107 -144T99 -154T92 -162L90 -164H91Q101 -167 151 -167Q189 -167 211 -155Q234 -144 254 -122T282 -75Q288 -56 298 -13Q311 35 311 43ZM384 328L380 339Q377 350 375 354T369 368T359 382T346 393T328 402T306 405Q262 405 221 352Q191 313 171 233T151 117Q151 38 213 38Q269 38 323 108L331 118L384 328Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3121,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(3587,0) translate(0 -0.5)"><path data-c="7C" d="M139 -249H137Q125 -249 119 -235V251L120 737Q130 750 139 750Q152 750 159 735V-235Q151 -249 141 -249H139Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(3865,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4226,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(4692,0)"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z" style="stroke-width:3;"></path></g><g data-mml-node="mi" transform="translate(5264,0)"><path data-c="1D461" d="M26 385Q19 392 19 395Q19 399 22 411T27 425Q29 430 36 430T87 431H140L159 511Q162 522 166 540T173 566T179 586T187 603T197 615T211 624T229 626Q247 625 254 615T261 596Q261 589 252 549T232 470L222 433Q222 431 272 431H323Q330 424 330 420Q330 398 317 385H210L174 240Q135 80 135 68Q135 26 162 26Q197 26 230 60T283 144Q285 150 288 151T303 153H307Q322 153 322 145Q322 142 319 133Q314 117 301 95T267 48T216 6T155 -11Q125 -11 98 4T59 56Q57 64 57 83V101L92 241Q127 382 128 383Q128 385 77 385H26Z" style="stroke-width:3;"></path></g><g data-mml-node="mo" transform="translate(5625,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z" style="stroke-width:3;"></path></g></g></g>',1)])])),e[21]||(e[21]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"p"),t("mo",{stretchy:"false"},"("),t("mi",null,"i"),t("mi",null,"m"),t("mi",null,"a"),t("mi",null,"g"),t("mi",null,"e"),t("mo",{"data-mjx-texclass":"ORD",stretchy:"false"},"|"),t("mi",null,"t"),t("mi",null,"e"),t("mi",null,"x"),t("mi",null,"t"),t("mo",{stretchy:"false"},")")])],-1))]),e[23]||(e[23]=o("，CLIP 等视觉-语言模型将文本编码为条件，扩散模型根据条件生成图像。图像编辑（Image Editing）任务中，可以通过修改扩散过程来实现图像修复、风格迁移、局部编辑。视频生成、3D 生成、分子设计等领域也开始应用扩散模型。扩散模型的成功证明了概率建模和迭代的去噪过程的强大，这为生成式 AI 开辟了新的方向。",-1))])])}const D=i(n,[["render",v]]);export{C as __pageData,D as default};
