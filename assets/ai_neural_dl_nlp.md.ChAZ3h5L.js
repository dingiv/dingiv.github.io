import{_ as n,c as i,o as s,ae as t}from"./chunks/framework.CDjunVez.js";const h=JSON.parse('{"title":"NLP","description":"","frontmatter":{"title":"NLP","order":20},"headers":[],"relativePath":"ai/neural/dl/nlp.md","filePath":"ai/neural/dl/nlp.md"}'),l={name:"ai/neural/dl/nlp.md"};function e(o,a,r,p,g,u){return s(),i("div",null,[...a[0]||(a[0]=[t(`<h1 id="自然语言处理-natural-language-processing" tabindex="-1">自然语言处理（Natural Language Processing） <a class="header-anchor" href="#自然语言处理-natural-language-processing" aria-label="Permalink to &quot;自然语言处理（Natural Language Processing）&quot;">​</a></h1><p>自然语言处理（NLP）是人工智能的重要分支，致力于让计算机理解、解释和生成人类语言。NLP 的目标是在计算机和人类语言之间架起桥梁，使机器能够处理和分析大量的自然语言数据。</p><h2 id="nlp-的核心挑战" tabindex="-1">NLP 的核心挑战 <a class="header-anchor" href="#nlp-的核心挑战" aria-label="Permalink to &quot;NLP 的核心挑战&quot;">​</a></h2><p>人类语言具有高度的复杂性和歧义性，这给计算机处理带来了诸多挑战：</p><ol><li><p><strong>歧义性</strong>：同一个词或句子可能有多种含义</p><ul><li>词汇歧义：&quot;银行&quot;可以指金融机构或河岸</li><li>结构歧义：&quot;我看见了一个人用望远镜&quot; - 谁用望远镜？</li></ul></li><li><p><strong>上下文依赖</strong>：词义和句意依赖于上下文</p><ul><li>&quot;这个苹果很好吃&quot;（水果）vs &quot;苹果发布了新产品&quot;（公司）</li></ul></li><li><p><strong>长距离依赖</strong>：句子中相距较远的词之间存在语义关联</p><ul><li>&quot;我昨天在超市买的那个苹果，今天吃起来很甜&quot;</li></ul></li><li><p><strong>知识推理</strong>：需要常识和背景知识</p><ul><li>&quot;他打开冰箱，发现牛奶过期了&quot; - 需要理解冰箱用来存储食物</li></ul></li><li><p><strong>语言多样性</strong>：不同语言、方言、口语表达方式各异</p></li></ol><h2 id="常见-nlp-任务类型" tabindex="-1">常见 NLP 任务类型 <a class="header-anchor" href="#常见-nlp-任务类型" aria-label="Permalink to &quot;常见 NLP 任务类型&quot;">​</a></h2><h3 id="基础任务" tabindex="-1">基础任务 <a class="header-anchor" href="#基础任务" aria-label="Permalink to &quot;基础任务&quot;">​</a></h3><h4 id="_1-分词-tokenization" tabindex="-1">1. 分词（Tokenization） <a class="header-anchor" href="#_1-分词-tokenization" aria-label="Permalink to &quot;1. 分词（Tokenization）&quot;">​</a></h4><p>将连续的文本切分成有意义的单元（词、字符、子词）。</p><p><strong>中文分词特点</strong>：</p><ul><li>中文没有天然的词边界（不像英文有空格）</li><li>需要专门的分词算法（如结巴分词、HanLP）</li></ul><p><strong>子词分词（Subword Tokenization）</strong>：</p><ul><li>BPE（Byte Pair Encoding）</li><li>WordPiece（BERT 使用）</li><li>SentencePiece（T5、LLaMA 使用）</li></ul><p><strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>原文：自然语言处理很有趣</span></span>
<span class="line"><span>分词：自然 / 语言 / 处理 / 很 / 有趣</span></span>
<span class="line"><span></span></span>
<span class="line"><span>英文：Natural Language Processing is interesting</span></span>
<span class="line"><span>分词：Natural / Language / Processing / is / interesting</span></span></code></pre></div><h4 id="_2-词性标注-part-of-speech-tagging" tabindex="-1">2. 词性标注（Part-of-Speech Tagging） <a class="header-anchor" href="#_2-词性标注-part-of-speech-tagging" aria-label="Permalink to &quot;2. 词性标注（Part-of-Speech Tagging）&quot;">​</a></h4><p>为每个词标注其词性（名词、动词、形容词等）。</p><p><strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>The/DT cat/NN sits/VBZ on/IN the/DT mat/NN</span></span>
<span class="line"><span>那/DT 只/M 猫/NN 坐/VV 在/P 垫子/NN 上/LC</span></span></code></pre></div><h4 id="_3-命名实体识别-named-entity-recognition-ner" tabindex="-1">3. 命名实体识别（Named Entity Recognition, NER） <a class="header-anchor" href="#_3-命名实体识别-named-entity-recognition-ner" aria-label="Permalink to &quot;3. 命名实体识别（Named Entity Recognition, NER）&quot;">​</a></h4><p>识别文本中的实体（人名、地名、组织名、时间等）。</p><p><strong>标注格式</strong>：常用 BIO 标注</p><ul><li>B (Begin)：实体开始</li><li>I (Inside)：实体内部</li><li>O (Outside)：非实体</li></ul><p><strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>输入：苹果公司的CEO蒂姆·库克在北京发表演讲</span></span>
<span class="line"><span>输出：</span></span>
<span class="line"><span>  苹果公司 -&gt; 组织</span></span>
<span class="line"><span>  蒂姆·库克 -&gt; 人名</span></span>
<span class="line"><span>  北京 -&gt; 地名</span></span></code></pre></div><p><strong>应用</strong>：信息抽取、知识图谱构建、智能客服</p><h3 id="理解任务" tabindex="-1">理解任务 <a class="header-anchor" href="#理解任务" aria-label="Permalink to &quot;理解任务&quot;">​</a></h3><h4 id="_4-文本分类-text-classification" tabindex="-1">4. 文本分类（Text Classification） <a class="header-anchor" href="#_4-文本分类-text-classification" aria-label="Permalink to &quot;4. 文本分类（Text Classification）&quot;">​</a></h4><p>将文本分配到预定义的类别。</p><p><strong>常见子任务</strong>：</p><ul><li><strong>情感分析</strong>：判断文本的情感倾向（正面、负面、中性）</li><li><strong>主题分类</strong>：将文档归类到不同主题（体育、科技、娱乐等）</li><li><strong>垃圾邮件检测</strong>：识别垃圾邮件</li><li><strong>意图识别</strong>：理解用户意图（对话系统）</li></ul><p><strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>文本：&quot;这家餐厅的菜品非常美味，服务也很周到！&quot;</span></span>
<span class="line"><span>分类：正面情感（Positive）</span></span></code></pre></div><p><strong>方法演变</strong>：</p><ul><li>传统：TF-IDF + 朴素贝叶斯/SVM</li><li>深度学习：CNN、LSTM、BERT</li></ul><h4 id="_5-文本相似度计算" tabindex="-1">5. 文本相似度计算 <a class="header-anchor" href="#_5-文本相似度计算" aria-label="Permalink to &quot;5. 文本相似度计算&quot;">​</a></h4><p>衡量两段文本的语义相似程度。</p><p><strong>应用场景</strong>：</p><ul><li>搜索引擎：查询和文档的匹配</li><li>问答系统：找到相似的历史问题</li><li>去重：检测重复内容</li><li>推荐系统：基于内容的推荐</li></ul><p><strong>方法</strong>：</p><ul><li>余弦相似度（基于词向量）</li><li>编辑距离（Levenshtein Distance）</li><li>语义相似度（BERT、Sentence-BERT）</li></ul><h4 id="_6-阅读理解与问答-question-answering" tabindex="-1">6. 阅读理解与问答（Question Answering） <a class="header-anchor" href="#_6-阅读理解与问答-question-answering" aria-label="Permalink to &quot;6. 阅读理解与问答（Question Answering）&quot;">​</a></h4><p>给定文本（上下文）和问题，从文本中找出答案或生成答案。</p><p><strong>类型</strong>：</p><ul><li><strong>抽取式问答</strong>：答案是原文中的片段（SQuAD）</li><li><strong>生成式问答</strong>：生成新的答案文本</li><li><strong>多跳推理</strong>：需要综合多个信息片段</li></ul><p><strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>上下文：苹果公司成立于1976年，总部位于加利福尼亚州库比蒂诺。</span></span>
<span class="line"><span>问题：苹果公司的总部在哪里？</span></span>
<span class="line"><span>答案：加利福尼亚州库比蒂诺</span></span></code></pre></div><h4 id="_7-自然语言推理-natural-language-inference-nli" tabindex="-1">7. 自然语言推理（Natural Language Inference, NLI） <a class="header-anchor" href="#_7-自然语言推理-natural-language-inference-nli" aria-label="Permalink to &quot;7. 自然语言推理（Natural Language Inference, NLI）&quot;">​</a></h4><p>判断两个句子之间的逻辑关系。</p><p><strong>关系类型</strong>：</p><ul><li><strong>蕴含（Entailment）</strong>：前提可以推出假设</li><li><strong>矛盾（Contradiction）</strong>：前提与假设相矛盾</li><li><strong>中性（Neutral）</strong>：无法判断</li></ul><p><strong>示例</strong>：</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>前提：一个女人在喝咖啡</span></span>
<span class="line"><span>假设：一个人在喝饮料</span></span>
<span class="line"><span>关系：蕴含（Entailment）</span></span></code></pre></div><h3 id="生成任务" tabindex="-1">生成任务 <a class="header-anchor" href="#生成任务" aria-label="Permalink to &quot;生成任务&quot;">​</a></h3><h4 id="_8-机器翻译-machine-translation" tabindex="-1">8. 机器翻译（Machine Translation） <a class="header-anchor" href="#_8-机器翻译-machine-translation" aria-label="Permalink to &quot;8. 机器翻译（Machine Translation）&quot;">​</a></h4><p>将一种语言的文本翻译成另一种语言。</p><p><strong>发展历程</strong>：</p><ul><li><strong>基于规则</strong>：手工编写翻译规则</li><li><strong>统计机器翻译（SMT）</strong>：基于大规模平行语料</li><li><strong>神经机器翻译（NMT）</strong>：Seq2Seq + Attention（2014-2017）</li><li><strong>Transformer 翻译</strong>：Google Translate、DeepL（2017-至今）</li></ul><p><strong>挑战</strong>：</p><ul><li>歧义处理</li><li>文化差异</li><li>罕见词翻译</li><li>保持语序和语法的流畅性</li></ul><h4 id="_9-文本摘要-text-summarization" tabindex="-1">9. 文本摘要（Text Summarization） <a class="header-anchor" href="#_9-文本摘要-text-summarization" aria-label="Permalink to &quot;9. 文本摘要（Text Summarization）&quot;">​</a></h4><p>生成文本的简洁摘要。</p><p><strong>类型</strong>：</p><ul><li><strong>抽取式摘要</strong>：选取原文中的关键句子</li><li><strong>生成式摘要</strong>：生成新的总结性文本</li></ul><p><strong>应用</strong>：新闻摘要、会议纪要、文献综述</p><h4 id="_10-对话系统-dialogue-systems" tabindex="-1">10. 对话系统（Dialogue Systems） <a class="header-anchor" href="#_10-对话系统-dialogue-systems" aria-label="Permalink to &quot;10. 对话系统（Dialogue Systems）&quot;">​</a></h4><p>与用户进行自然语言交互。</p><p><strong>类型</strong>：</p><ul><li><strong>任务导向型</strong>：完成特定任务（订票、客服）</li><li><strong>闲聊型</strong>：开放域对话（聊天机器人）</li><li><strong>问答型</strong>：回答用户问题</li></ul><p><strong>关键模块</strong>：</p><ul><li>自然语言理解（NLU）</li><li>对话管理（DM）</li><li>自然语言生成（NLG）</li></ul><h4 id="_11-文本生成-text-generation" tabindex="-1">11. 文本生成（Text Generation） <a class="header-anchor" href="#_11-文本生成-text-generation" aria-label="Permalink to &quot;11. 文本生成（Text Generation）&quot;">​</a></h4><p>根据给定的提示或条件生成连贯的文本。</p><p><strong>应用</strong>：</p><ul><li>创意写作：诗歌、故事生成</li><li>代码生成：GitHub Copilot</li><li>数据增强：生成训练样本</li><li>对话回复生成</li></ul><p><strong>评估指标</strong>：</p><ul><li>BLEU：机器翻译评估</li><li>ROUGE：摘要评估</li><li>Perplexity：语言模型困惑度</li></ul><h2 id="nlp-神经网络架构演进" tabindex="-1">NLP 神经网络架构演进 <a class="header-anchor" href="#nlp-神经网络架构演进" aria-label="Permalink to &quot;NLP 神经网络架构演进&quot;">​</a></h2><h3 id="传统方法的局限" tabindex="-1">传统方法的局限 <a class="header-anchor" href="#传统方法的局限" aria-label="Permalink to &quot;传统方法的局限&quot;">​</a></h3><p>在深度学习之前，NLP 主要依赖：</p><ul><li><strong>词袋模型（Bag of Words）</strong>：丢失词序信息</li><li><strong>TF-IDF</strong>：无法捕捉语义</li><li><strong>N-gram</strong>：维度爆炸，稀疏性问题</li></ul><p><strong>词向量革命</strong>（Word2Vec, 2013）：</p><ul><li>Skip-gram 和 CBOW 模型</li><li>将词映射到稠密的低维向量空间</li><li>捕捉词的语义关系：&quot;king - man + woman ≈ queen&quot;</li></ul>`,83)])])}const d=n(l,[["render",e]]);export{h as __pageData,d as default};
