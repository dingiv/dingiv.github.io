import{_ as i,o as a,c as n,ah as t}from"./chunks/framework.BvDvRtye.js";const o=JSON.parse('{"title":"Triton","description":"","frontmatter":{},"headers":[],"relativePath":"ai/compute/api/triton.md","filePath":"ai/compute/api/triton.md"}'),h={name:"ai/compute/api/triton.md"};function l(k,s,p,e,r,E){return a(),n("div",null,[...s[0]||(s[0]=[t(`<h1 id="triton" tabindex="-1">Triton <a class="header-anchor" href="#triton" aria-label="Permalink to “Triton”">​</a></h1><p>Triton 是 OpenAI 开发的 GPU 编程语言，旨在提供比 CUDA 更高层抽象的同时，保持接近手写 CUDA 的性能。它的设计哲学是&quot;让 AI 研究者能够轻松编写高性能 GPU kernel&quot;，无需深入了解 GPU 架构、shared memory、warp shuffle 等底层概念。</p><h2 id="为什么需要-triton" tabindex="-1">为什么需要 Triton <a class="header-anchor" href="#为什么需要-triton" aria-label="Permalink to “为什么需要 Triton”">​</a></h2><p>CUDA 编程的学习曲线陡峭，需要理解 GPU 的硬件架构（SM、warp、shared memory bank conflict）、手动管理线程块调度、优化内存访问模式（coalescing、padding）。编写一个高效的矩阵乘法 kernel 需要数百行代码，且针对不同 GPU 架构（Ampere vs Hopper）需要重新调优。</p><p>Triton 将抽象级别提高到更接近数学表达，开发者只需编写&quot;每个输出元素如何计算&quot;，编译器自动处理线程映射、内存分块、shared memory 管理。这大幅降低了开发门槛，一个矩阵乘法 kernel 仅需约 50 行 Triton 代码，且性能可达手写 CUDA 的 90% 以上。</p><h2 id="核心概念" tabindex="-1">核心概念 <a class="header-anchor" href="#核心概念" aria-label="Permalink to “核心概念”">​</a></h2><p>Triton 的程序以 <code>@triton.jit</code> 装饰的函数表示，该函数将被编译为 GPU kernel。函数的参数包括输入输出张量的指针、形状、步长（stride），以及编译时常量（如 <code>BLOCK_SIZE: tl.constexpr</code>）。kernel 内部使用 Triton 语言（基于 Python 的 DSL）编写，包括 <code>tl.load</code>（加载数据）、<code>tl.store</code>（存储数据）、<code>tl.dot</code>（矩阵乘法）、<code>tl.reduce</code>（归约操作）等原语。</p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> triton</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> triton.language </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tl</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@triton.jit</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> add_kernel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x_ptr, y_ptr, output_ptr, n_elements, BLOCK_SIZE: tl.constexpr):</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 每个 program 处理一个 BLOCK_SIZE 的数据</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    pid </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tl.program_id(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">axis</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    block_start </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> pid </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> BLOCK_SIZE</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    offsets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> block_start </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tl.arange(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">BLOCK_SIZE</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    mask </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> offsets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">&lt;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> n_elements</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 加载数据</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tl.load(x_ptr </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> offsets, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mask</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mask)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> tl.load(y_ptr </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> offsets, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mask</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mask)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> x </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> y</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 存储数据</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    tl.store(output_ptr </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">+</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> offsets, output, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">mask</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">mask)</span></span></code></pre></div><p>Triton 的抽象模型是&quot;program&quot;而非&quot;thread&quot;。一个 program 处理一个数据块（block），编译器自动将 program 映射到 GPU 的线程块，并管理线程同步。这简化了并行编程，因为开发者无需手动计算 thread ID、block ID、grid size。</p><h2 id="自动调优" tabindex="-1">自动调优 <a class="header-anchor" href="#自动调优" aria-label="Permalink to “自动调优”">​</a></h2><p>Triton 的 <code>triton.autotune</code> 可自动搜索最优配置（block size、num_stages、num_warps）。对于矩阵乘法，block size 影响 shared memory 使用率，num_stages 影响流水线深度，num_warps 影响 warp 占用。这些参数的最优值依赖于硬件架构和数据形状，手动调优需要大量实验。<code>autotune</code> 通过运行不同配置，选择性能最优的配置，无需人工干预。</p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@triton.autotune</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    configs</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        triton.Config({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;BLOCK_SIZE&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">128</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_warps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        triton.Config({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;BLOCK_SIZE&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_warps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">8</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">        triton.Config({</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;BLOCK_SIZE&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">: </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">512</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">}, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">num_warps</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">16</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">),</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    ],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    key</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;n_elements&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;">@triton.jit</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> add_kernel</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(...):</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    ...</span></span></code></pre></div><h2 id="pytorch-一等公民" tabindex="-1">PyTorch 一等公民 <a class="header-anchor" href="#pytorch-一等公民" aria-label="Permalink to “PyTorch 一等公民”">​</a></h2><p>Triton kernel 可通过 <code>torch.compile</code> 或 <code>torch.ops.load_custom_op</code> 集成到 PyTorch 模型中。PyTorch 2.0 原生支持 Triton，<code>torch.compile</code> 会自动将符合模式的算子编译为 Triton kernel（如逐元素操作、归约操作）。这无需修改模型代码，只需添加 <code>torch.compile(model)</code> 即可享受 Triton 的性能提升。自此，PyTorch 的强势推行，Triton 已成为 PyTorch 平台的一等公民。</p><p>对于自定义算子，可通过 <code>torch.library.custom_op</code> 注册 Triton kernel：</p><div class="language-python"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark" style="--shiki-light:#24292e;--shiki-dark:#e1e4e8;--shiki-light-bg:#fff;--shiki-dark-bg:#24292e;" tabindex="0" dir="ltr"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> triton_add</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x, y):</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    output </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> torch.empty_like(x)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    n_elements </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> output.numel()</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    grid </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;"> lambda</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> meta: (triton.cdiv(n_elements, meta[</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;BLOCK_SIZE&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]),)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    add_kernel[grid](x, y, output, n_elements, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">BLOCK_SIZE</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">256</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">    return</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> output</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;"># 注册为 PyTorch 算子</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.library.define(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mylib::triton_add&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;(Tensor, Tensor) -&gt; Tensor&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">torch.library.impl(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;mylib::triton_add&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;CUDA&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, triton_add)</span></span></code></pre></div><h2 id="性能对比" tabindex="-1">性能对比 <a class="header-anchor" href="#性能对比" aria-label="Permalink to “性能对比”">​</a></h2><p>Triton 官方 benchmark 显示，对于常见算子（逐元素操作、Softmax、LayerNorm），Triton 的性能可达手写 CUDA 的 85-95%。对于矩阵乘法，Triton 的性能约为 cuBLAS（NVIDIA 官方库）的 70-80%，差距主要来自 cuBLAS 针对特定 GPU 架构的手写汇编优化。</p><p>Triton 的优势在于开发效率。一个 Triton kernel 从编写、调试、调优到部署，通常仅需 1-2 天，而手写 CUDA 需要 1-2 周。对于快速迭代的研究场景（尝试新的 Attention 机制、新的归一化方法），Triton 是更实用的选择。</p><h2 id="局限性" tabindex="-1">局限性 <a class="header-anchor" href="#局限性" aria-label="Permalink to “局限性”">​</a></h2><p>Triton 的抽象级别高于 CUDA，但也因此牺牲了部分性能控制力。对于需要极致优化的算子（如 FlashAttention-2 的手写 assembly），Triton 难以达到同等性能。此外，Triton 的生态系统仍在发展中，调试工具（<code>triton.testing</code>）和性能分析工具（<code>triton.testing.do_bench</code>）不如 CUDA 成熟。</p><p>Triton 目前支持 NVIDIA GPU 和 AMD GPU（通过 ROCm），不支持 CPU 和其他加速器（如 TPU、NPU）。对于非 CUDA 平台，需要考虑其他方案（如 OpenCL、SYCL）。</p><p>Triton 只定义了数据面 DSL，未能实现控制面代码的封装屏蔽，对于不同的厂商硬件上的控制面代码，例如：显存管理和通信控制等，依然需要上层的 AI 引擎层来管理和调度。</p><h2 id="未来展望" tabindex="-1">未来展望 <a class="header-anchor" href="#未来展望" aria-label="Permalink to “未来展望”">​</a></h2><p>Triton 的发展方向包括：更好的自动调优（基于机器学习的配置搜索）、更丰富的标准库（卷积、RNN、Transformer）、更完善的调试工具（interleaved execution、race condition 检测）。OpenAI 正在使用 Triton 重写 PyTorch 的标准算子，未来 <code>torch.nn.functional</code> 的大部分算子可能由 Triton 实现，而非 cuDNN。</p><p>Triton 有望成为 AI 领域的&quot;Vulkan&quot;——跨平台、高性能、易用性兼备的 GPU 编程语言。与 Vulkan 一样，Triton 的成功依赖于生态建设（IDE 支持、性能分析工具、第三方库），这需要社区的共同努力。</p>`,26)])])}const g=i(h,[["render",l]]);export{o as __pageData,g as default};
