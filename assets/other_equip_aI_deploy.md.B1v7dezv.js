import{_ as d,c as a,o as e,ae as r}from"./chunks/framework.CDjunVez.js";const _=JSON.parse('{"title":"AI 模型硬件","description":"","frontmatter":{},"headers":[],"relativePath":"other/equip/aI_deploy.md","filePath":"other/equip/aI_deploy.md"}'),i={name:"other/equip/aI_deploy.md"};function o(s,t,n,l,p,h){return e(),a("div",null,[...t[0]||(t[0]=[r(`<h1 id="ai-模型硬件" tabindex="-1">AI 模型硬件 <a class="header-anchor" href="#ai-模型硬件" aria-label="Permalink to &quot;AI 模型硬件&quot;">​</a></h1><p>根据 Deepseek 蒸馏模型档位来进行划分：</p><table tabindex="0"><thead><tr><th>参数规模</th><th>训练显存</th><th>推荐配置</th></tr></thead><tbody><tr><td>70B</td><td>182GiB</td><td>2 路 numa + rtx PRO 4000 24G * 8</td></tr><tr><td>32B</td><td>84</td><td>2 路 numa + rtx 3080 20G * 10</td></tr><tr><td></td><td></td><td>2 路 numa + rtx 5060Ti 16G * 8</td></tr><tr><td>14B</td><td>37</td><td>消费级 rtx4090 48G、工作级 rtx</td></tr><tr><td>8B</td><td>21</td><td>消费级 rtx3090 24G、rtx4090 48G</td></tr><tr><td>1.5B</td><td>4</td><td>消费级 PC</td></tr></tbody></table><p>训练使用的显存 = 参数规模 * 2 GiB/B * 1.3 部署使用的内存 = 参数规模 * 1 GiB/B * 1.3</p><p>部署时所需要的显存是训练时的一半。</p><div class="language- vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span>// 70B</span></span>
<span class="line"><span>70B * 2GiB/B * 1.3 = 182 GiB</span></span></code></pre></div><h2 id="大显存显卡" tabindex="-1">大显存显卡 <a class="header-anchor" href="#大显存显卡" aria-label="Permalink to &quot;大显存显卡&quot;">​</a></h2><table tabindex="0"><thead><tr><th></th><th></th><th></th><th></th></tr></thead><tbody><tr><td>rtx 5060Ti</td><td>Blackwell</td><td>16</td><td>3000</td></tr><tr><td>rtx 4090 定制</td><td>Lovelace</td><td>48</td><td>20000</td></tr><tr><td>rtx 3080 定制</td><td>Amphere</td><td>20</td><td>3000</td></tr><tr><td>rtx pro 4000</td><td>Blackwell</td><td>24</td><td>10000</td></tr></tbody></table>`,8)])])}const u=d(i,[["render",o]]);export{_ as __pageData,u as default};
