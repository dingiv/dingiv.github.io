import{_ as e,o as t,c as p,ah as o}from"./chunks/framework.CJUjh4G6.js";const P=JSON.parse('{"title":"预训练","description":"","frontmatter":{"title":"预训练","order":0},"headers":[],"relativePath":"ai/llm/gpt/pre.md","filePath":"ai/llm/gpt/pre.md"}'),r={name:"ai/llm/gpt/pre.md"};function i(l,a,n,h,s,d){return t(),p("div",null,[...a[0]||(a[0]=[o('<h1 id="预训练" tabindex="-1">预训练 <a class="header-anchor" href="#预训练" aria-label="Permalink to “预训练”">​</a></h1><p>预训练是大语言模型能力的基础建设阶段，也是最具技术挑战和资源消耗的环节。这一阶段的目标是让模型通过自监督学习，从海量文本中掌握语言的统计规律、世界知识和推理能力。简单来说，预训练是让模型学会&quot;如何说话&quot;——掌握语法、语义、常识知识，但还不会按照指令回答问题。</p><h2 id="预训练的基本原理" tabindex="-1">预训练的基本原理 <a class="header-anchor" href="#预训练的基本原理" aria-label="Permalink to “预训练的基本原理”">​</a></h2><p>预训练的核心思想是利用互联网上几乎无限的无标注文本，通过设计合适的自监督任务，让模型学习到通用的语言表示。最常用的任务是&quot;预测下一个 token&quot;（Next Token Prediction）：给定一个文本序列的前面部分，让模型预测接下来的词。例如，看到&quot;人工智能的发展源于&quot;，模型需要预测&quot;1956 年的达特茅斯会议&quot;这样的后续内容。</p><p>这种训练方式的巧妙之处在于，训练信号天然存在于文本本身——每个 token 的下一个 token 就是标签，无需人工标注。模型通过数万亿次的预测尝试，逐渐学会了语言的统计规律。更重要的是，这种预测任务迫使模型压缩输入文本中的信息到模型参数中，因为只有理解了上下文，才能准确预测下一个词。</p><p>从信息论角度看，预训练实际上是在学习数据的压缩表示。模型参数越多，能够存储的信息量越大，预测能力也越强。这也是为什么模型规模从 GPT-2 的 15 亿参数增长到 GPT-3 的 1750 亿，再到 GPT-4 的万亿级别——规模越大，模型能够学习和记忆的知识越多。</p><h2 id="数据工程" tabindex="-1">数据工程 <a class="header-anchor" href="#数据工程" aria-label="Permalink to “数据工程”">​</a></h2><p>数据质量比数据数量更重要，这是预训练实践中最重要的经验。原始的互联网文本充满噪声：广告、重复内容、乱码、低质量的 SEO 文章，这些都会严重影响模型性能。数据清洗是第一步，需要过滤掉明显低质量的内容。常用的过滤规则包括：语言检测（去除非目标语言文本）、困惑度过滤（使用小型语言模型识别不自然的文本）、启发式规则（去除过多标点符号或特殊字符的文本）。</p><p>数据去重同样关键。互联网上存在大量重复或高度相似的内容，如果不去重，模型会&quot;记住&quot;这些重复出现的文本，导致训练集上的表现虚高，但泛化能力差。实践中使用精确去重（完全相同的文档）和近似去重（使用 MinHash LSH 等算法检测相似文档）相结合，能将数据集规模减少 30-50%，同时提升模型性能。</p><p>数据配比是根据目标任务调整不同数据源的比例。代码数据能显著提升模型的推理能力，学术论文增强专业知识，高质量的网页文本提供通识能力，书籍数据提升叙事和长文本理解能力。一个常见的配比是：代码 10%、论文 15%、书籍 20%、网页 55%，具体比例会根据目标任务调整。值得注意的是，代码数据的价值被广泛认可——代码包含严谨的逻辑结构，训练时加入代码能提升模型的数学推理和问题分解能力。</p><p>2025 年的一个趋势是合成数据的使用。随着人类高质量文本接近枯竭，研究者开始使用强模型（如 GPT-4）生成训练数据。合成数据的关键是质量控制——使用复杂指令链让模型生成多样化、高质量的文本，然后用弱模型过滤掉可能包含错误的内容。这种方法在代码生成、数学推理等任务上已经取得显著效果。</p><h2 id="训练基础设施" tabindex="-1">训练基础设施 <a class="header-anchor" href="#训练基础设施" aria-label="Permalink to “训练基础设施”">​</a></h2><p>预训练需要在数千张 GPU 上运行数周甚至数月，这对训练基础设施提出了极高要求。分布式训练框架是基础——DeepSpeed、Megatron-LM、Alpa 等框架处理了模型并行、数据并行、流水线并行的复杂性，让开发者能够像写单机代码一样写分布式训练。</p><p>模型并行将模型的不同层分布到不同的 GPU 上，每张 GPU 只存储模型的一部分参数。前向传播时，数据需要在 GPU 之间传递激活值，反向传播时传递梯度。通信开销是主要瓶颈，因此需要仔细设计并行策略——减少跨设备通信、使用计算和通信重叠（在计算的同时进行数据传输）。流水线并行将模型的不同层分组到不同的 GPU 上，每个 GPU 处理一批数据的几层，然后传递给下一组 GPU，能提高 GPU 利用率但增加了实现复杂度。</p><p>混合精度训练（FP16/BF16）是标准实践。使用半精度浮点数能减少内存占用、提高计算速度，但需要处理数值稳定性问题——梯度过小会下溢，梯度过大会溢出。常用的解决方案是损失缩放（loss scaling），在反向传播前将损失乘以一个大数，更新参数后再除回来。BF16（Brain Float 16）因为指数位与 FP32 相同，数值范围更大，逐渐成为主流选择。</p><p>训练稳定性是另一个挑战。大规模训练经常遇到梯度爆炸（loss 突然变成 NaN）、损失尖峰（loss 短暂飙升后恢复）、权重发散等问题。常用的防护措施包括梯度裁剪（限制梯度最大值）、自适应学习率（AdamW 优化器）、warm-up 调度（训练初期使用较小的学习率）。即使如此，训练崩溃仍时有发生，因此需要定期保存检查点（checkpoint），以便从崩溃点恢复。</p><h2 id="超参数调优" tabindex="-1">超参数调优 <a class="header-anchor" href="#超参数调优" aria-label="Permalink to “超参数调优”">​</a></h2><p>学习率调度对训练效果影响巨大。预训练通常使用 cosine 学习率衰减——初始学习率经过 warm-up 期逐渐增加到最大值，然后按照余弦曲线衰减到接近零。warm-up 期通常占总训练步数的 5-10%，防止训练初期的大梯度更新破坏预训练权重。最大学习率的选择需要实验确定，太大可能导致训练不稳定，太小则训练速度慢。常用的启发式规则是：批量大小越大，学习率按比例增大（线性缩放规则）。</p><p>批量大小影响训练速度和模型质量。大批量训练能提高 GPU 利用率，但可能损害泛化能力。实践中常用&quot;梯度累积&quot;来模拟大批量——每个小批量计算梯度但不立即更新参数，而是累积多个小批量的梯度后再更新。这样既保持了小批量的泛化优势，又获得了大批量的训练速度。常见的配置是每张 GPU 的批量大小为 4-8，累积 8-16 步后再更新。</p><p>权重衰减（weight decay）是正则化技术，通过对大权重施加惩罚防止过拟合。AdamW 优化器将权重衰减与自适应学习率解耦，成为预训练的标准选择。权重衰减系数通常设为 0.01-0.1，具体值需要验证集调整。值得注意的是，权重衰减对大模型的影响较小——大模型本身就具有很强的正则化效应（参数量远大于训练数据量）。</p><p>训练步数的确定需要平衡计算预算和模型性能。一个有用的经验法则是&quot;训练到过拟合&quot;——持续训练直到验证集损失不再下降甚至开始上升，然后回退到最佳检查点。实践中，预训练通常需要数千亿 token 的训练数据，模型规模越大，需要的数据量越多。Chinchilla 最优规模理论指出，给定计算预算，模型大小和数据量应该按比例增长——不是一味追求大模型，而是平衡模型和数据。</p><h2 id="涌现能力" tabindex="-1">涌现能力 <a class="header-anchor" href="#涌现能力" aria-label="Permalink to “涌现能力”">​</a></h2><p>当模型规模突破临界点后，会突然展现小模型不具备的能力。这种现象被称为&quot;涌现能力&quot;，包括零样本学习（无需示例即可完成新任务）、上下文学习（从几个示例中学习新任务）、思维链推理（通过分步推理解决复杂问题）。这些能力不是显式训练的，而是从大量训练数据中自发涌现的。</p><p>涌现能力的临界点取决于任务难度。简单的文本生成任务（如续写故事）在小模型上就能实现，而复杂的推理任务（如数学证明、代码生成）需要更大的模型。研究表明，涌现能力不是渐进式的，而是&quot;相变&quot;式的——模型规模小于临界点时，能力接近随机；超过临界点后，能力突然提升。这也解释了为什么 GPT-3 的出现如此震撼——它是第一个跨越涌现临界点的模型，展示了令人惊讶的推理和生成能力。</p><p>从工程角度看，涌现能力带来了新的挑战。小模型可以预测其行为，而大模型的能力难以在训练前预判。这要求开发者在训练过程中持续评估模型在多样化任务上的表现，而不仅仅是看损失曲线。评估集需要覆盖推理、编程、数学、对话等多种能力，以便及时发现和引导涌现能力的出现。</p>',25)])])}const u=e(r,[["render",i]]);export{P as __pageData,u as default};
