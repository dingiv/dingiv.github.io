import{_ as o,o as a,c as l,ah as Q,j as t,a as T}from"./chunks/framework.BvDvRtye.js";const C=JSON.parse('{"title":"主流引擎","description":"","frontmatter":{"title":"主流引擎","order":10},"headers":[],"relativePath":"ai/compute/engine/index.md","filePath":"ai/compute/engine/index.md"}'),n={name:"ai/compute/engine/index.md"},s={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},r={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"5.832ex",height:"2.452ex",role:"img",focusable:"false",viewBox:"0 -833.9 2577.6 1083.9","aria-hidden":"true"},i={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},d={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.618ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 2041 1000","aria-hidden":"true"},m={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},p={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.566ex"},xmlns:"http://www.w3.org/2000/svg",width:"4.618ex",height:"2.262ex",role:"img",focusable:"false",viewBox:"0 -750 2041 1000","aria-hidden":"true"},h={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},x={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.489ex",height:"1.532ex",role:"img",focusable:"false",viewBox:"0 -666 1100 677","aria-hidden":"true"},g={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},u={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.025ex"},xmlns:"http://www.w3.org/2000/svg",width:"1.357ex",height:"1.025ex",role:"img",focusable:"false",viewBox:"0 -442 600 453","aria-hidden":"true"},w={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},c={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.186ex"},xmlns:"http://www.w3.org/2000/svg",width:"9.042ex",height:"1.731ex",role:"img",focusable:"false",viewBox:"0 -683 3996.6 765","aria-hidden":"true"},f={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},L={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.05ex"},xmlns:"http://www.w3.org/2000/svg",width:"2.371ex",height:"1.595ex",role:"img",focusable:"false",viewBox:"0 -683 1048 705","aria-hidden":"true"},b={class:"MathJax",jax:"SVG",style:{direction:"ltr",position:"relative"}},k={style:{overflow:"visible","min-height":"1px","min-width":"1px","vertical-align":"-0.357ex"},xmlns:"http://www.w3.org/2000/svg",width:"9.874ex",height:"1.902ex",role:"img",focusable:"false",viewBox:"0 -683 4364.5 840.8","aria-hidden":"true"};function v(y,e,M,H,P,_){return a(),l("div",null,[e[28]||(e[28]=Q("",10)),t("p",null,[e[2]||(e[2]=T("KV Cache 优化是推理性能的核心。标准 Attention 需要缓存所有历史位置的 Key 和 Value 张量，每次生成新 Token 时与历史 KV 做矩阵乘法，计算复杂度为 ",-1)),t("mjx-container",s,[(a(),l("svg",r,[...e[0]||(e[0]=[Q("",1)])])),e[1]||(e[1]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"O"),t("mo",{stretchy:"false"},"("),t("msup",null,[t("mi",null,"n"),t("mn",null,"2")]),t("mo",{stretchy:"false"},")")])],-1))]),e[3]||(e[3]=T("。FlashAttention 通过分块计算减少内存访问次数，将显存带宽利用率从 20% 提升到 80% 以上，推理速度提升 2-3 倍。PagedAttention 进一步将 KV Cache 分页管理，支持显存不足时的动态换页和共享。",-1))]),e[29]||(e[29]=Q("",13)),t("p",null,[e[8]||(e[8]=T("显存容量是首要瓶颈。一个 7B 参数的模型，仅权重就需要约 14GB 显存（FP16），加上激活值、梯度、优化器状态，实际需求可能达到 60GB 以上，远超单卡容量。这催生了 ZeRO、FSDP 等显存优化技术，通过分片存储优化器状态、梯度和参数，将显存占用从 ",-1)),t("mjx-container",i,[(a(),l("svg",d,[...e[4]||(e[4]=[Q("",1)])])),e[5]||(e[5]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"O"),t("mo",{stretchy:"false"},"("),t("mn",null,"2"),t("mo",{stretchy:"false"},")")])],-1))]),e[9]||(e[9]=T(" 降至 ",-1)),t("mjx-container",m,[(a(),l("svg",p,[...e[6]||(e[6]=[Q("",1)])])),e[7]||(e[7]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"O"),t("mo",{stretchy:"false"},"("),t("mn",null,"1"),t("mo",{stretchy:"false"},")")])],-1))]),e[10]||(e[10]=T("。",-1))]),e[30]||(e[30]=t("p",null,"计算效率方面，大模型训练的浮点运算量巨大，GPT-3 175B 的训练需要约 3.14 × 10^23 FLOPs。单纯增加 GPU 数量会面临 Amdahl 定律的通信瓶颈，因此需要算子融合（如 FlashAttention）、混合精度训练（BF16/FP16）、编译优化（torch.compile）等技术提升单卡计算效率。",-1)),e[31]||(e[31]=t("p",null,"通信带宽是分布式训练的阿喀琉斯之踵。数据并行需要在每次迭代后同步梯度，模型并行则需要在前向/反向传播中频繁通信张量。NVLink 带宽约 400GB/s，而 PCIe 5.0 仅 32GB/s，跨节点 InfiniBand 通常低于 100GB/s。DeepSpeed、Megatron 通过通信与计算重叠（overlap）、梯度压缩、拓扑感知通信等手段缓解这一问题。",-1)),e[32]||(e[32]=t("h3",{id:"分布式策略",tabindex:"-1"},[T("分布式策略 "),t("a",{class:"header-anchor",href:"#分布式策略","aria-label":"Permalink to “分布式策略”"},"​")],-1)),e[33]||(e[33]=t("p",null,"从数据并行的朴素同步 SGD，到 3D 并行的复杂张量切分，不同策略在通信频率、显存占用、工程复杂度上各有取舍。",-1)),t("p",null,[e[15]||(e[15]=T("数据并行是最直观的方案：每个 GPU 持有完整模型副本，处理不同数据分片，通过 AllReduce 同步梯度。PyTorch DDP 封装了这一模式，但在大模型场景下，多副本的显存开销无法接受。ZeRO 进一步优化了数据并行，将优化器状态、梯度、参数分片到不同 GPU，仅在需要时通过 AllGather 重建，将显存占用从 ",-1)),t("mjx-container",h,[(a(),l("svg",x,[...e[11]||(e[11]=[Q("",1)])])),e[12]||(e[12]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mn",null,"2"),t("mi",null,"n")])],-1))]),e[16]||(e[16]=T(" 倍降至 1 倍（",-1)),t("mjx-container",g,[(a(),l("svg",u,[...e[13]||(e[13]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D45B",d:"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z",style:{"stroke-width":"3"}})])])],-1)])])),e[14]||(e[14]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"n")])],-1))]),e[17]||(e[17]=T(" 为 GPU 数量）。",-1))]),t("p",null,[e[24]||(e[24]=T("张量并行将模型的单个算子在多个 GPU 上切分。例如矩阵乘法 ",-1)),t("mjx-container",w,[(a(),l("svg",c,[...e[18]||(e[18]=[Q("",1)])])),e[19]||(e[19]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"Y"),t("mo",null,"="),t("mi",null,"X"),t("mi",null,"W")])],-1))]),e[25]||(e[25]=T("，可将权重 ",-1)),t("mjx-container",f,[(a(),l("svg",L,[...e[20]||(e[20]=[t("g",{stroke:"currentColor",fill:"currentColor","stroke-width":"0",transform:"scale(1,-1)"},[t("g",{"data-mml-node":"math"},[t("g",{"data-mml-node":"mi"},[t("path",{"data-c":"1D44A",d:"M436 683Q450 683 486 682T553 680Q604 680 638 681T677 682Q695 682 695 674Q695 670 692 659Q687 641 683 639T661 637Q636 636 621 632T600 624T597 615Q597 603 613 377T629 138L631 141Q633 144 637 151T649 170T666 200T690 241T720 295T759 362Q863 546 877 572T892 604Q892 619 873 628T831 637Q817 637 817 647Q817 650 819 660Q823 676 825 679T839 682Q842 682 856 682T895 682T949 681Q1015 681 1034 683Q1048 683 1048 672Q1048 666 1045 655T1038 640T1028 637Q1006 637 988 631T958 617T939 600T927 584L923 578L754 282Q586 -14 585 -15Q579 -22 561 -22Q546 -22 542 -17Q539 -14 523 229T506 480L494 462Q472 425 366 239Q222 -13 220 -15T215 -19Q210 -22 197 -22Q178 -22 176 -15Q176 -12 154 304T131 622Q129 631 121 633T82 637H58Q51 644 51 648Q52 671 64 683H76Q118 680 176 680Q301 680 313 683H323Q329 677 329 674T327 656Q322 641 318 637H297Q236 634 232 620Q262 160 266 136L501 550L499 587Q496 629 489 632Q483 636 447 637Q428 637 422 639T416 648Q416 650 418 660Q419 664 420 669T421 676T424 680T428 682T436 683Z",style:{"stroke-width":"3"}})])])],-1)])])),e[21]||(e[21]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("mi",null,"W")])],-1))]),e[26]||(e[26]=T(" 按列切分到 4 张卡，每张卡计算 ",-1)),t("mjx-container",b,[(a(),l("svg",k,[...e[22]||(e[22]=[Q("",1)])])),e[23]||(e[23]=t("mjx-assistive-mml",{unselectable:"on",display:"inline",style:{top:"0px",left:"0px",clip:"rect(1px, 1px, 1px, 1px)","-webkit-touch-callout":"none","-webkit-user-select":"none","-khtml-user-select":"none","-moz-user-select":"none","-ms-user-select":"none","user-select":"none",position:"absolute",padding:"1px 0px 0px 0px",border:"0px",display:"block",width:"auto",overflow:"hidden"}},[t("math",{xmlns:"http://www.w3.org/1998/Math/MathML"},[t("msub",null,[t("mi",null,"Y"),t("mi",null,"i")]),t("mo",null,"="),t("mi",null,"X"),t("msub",null,[t("mi",null,"W"),t("mi",null,"i")])])],-1))]),e[27]||(e[27]=T("，最后通过 AllConcat 拼接结果。这种方式无需复制模型，但每个算子完成后都需要通信，延迟敏感。Megatron-LM 首创了这一技术，用于训练 GPT-3 175B。",-1))]),e[34]||(e[34]=t("p",null,"流水线并行将模型的不同层分配到不同 GPU，形成流水线。GPU 1 计算第 1-12 层，GPU 2 计算 13-24 层，两者可并行处理不同样本。但流水线存在气泡（bubble）空转，需要通过微批次（micro-batch）调度和 1F1B 策略填充。PipeDream、PipeDream-2BW 是早期探索者。",-1)),e[35]||(e[35]=t("p",null,"3D 并行是上述三者的组合：在同一集群内同时使用数据、张量、流水线并行。通常在节点内使用张量并行（高带宽 NVLink），节点间使用流水线并行（跨节点通信少），最外层使用数据并行。Megatron-DeepSpeed 成功用此策略在 3072 张 A100 上训练了 1T 参数的模型。",-1))])}const A=o(n,[["render",v]]);export{C as __pageData,A as default};
