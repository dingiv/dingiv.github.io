import{_ as e,o as i,c as r,ah as t,ap as n}from"./chunks/framework.BvDvRtye.js";const m=JSON.parse('{"title":"神经网络","description":"","frontmatter":{"title":"神经网络","order":20},"headers":[],"relativePath":"ai/neural/index.md","filePath":"ai/neural/index.md"}'),l={name:"ai/neural/index.md"};function o(s,a,p,d,c,h){return i(),r("div",null,[...a[0]||(a[0]=[t('<h1 id="神经网络" tabindex="-1">神经网络 <a class="header-anchor" href="#神经网络" aria-label="Permalink to “神经网络”">​</a></h1><p>神经网络算法是构成连接主义 AI 学派的基石技术。它通过模拟生物大脑中神经元的工作方式，构建由大量相互连接的节点（神经元）组成的计算模型，能够从数据中自动学习复杂的模式和规律。</p><p>连接主义 AI 的三要素：<strong>数据、算法和算力</strong>。依赖于大量的数据进行训练，试图从数据中总结规律，数据越多，总结的规律就越精确越多。算法讨论的是如何去从数据中总结出规律。算力见<a href="/ai/compute/">AI 引擎章节</a>。</p><h2 id="基本原理" tabindex="-1">基本原理 <a class="header-anchor" href="#基本原理" aria-label="Permalink to “基本原理”">​</a></h2><p>神经网络由多个层（Layer）组成，每层包含多个神经元（Neuron）。每个神经元接收输入信号，通过权重（Weight）和偏置（Bias）进行加权求和，然后经过激活函数（Activation Function）处理，产生输出信号传递给下一层。</p><p>在推理阶段，数据以张量形式从神经网络输入进入，经过多个层次的张量变换，最后从输出层输出，以实现预测能力。</p><p>在训练阶段，以监督学习的形式，先进行正向预测，求解损失函数，然后使用梯度下降和反向传播算法（Backpropagation），微调神经网络的权重和偏置参数，在大量的数据上往复多次调整，使得模型得预测结果逐渐接近期望值。然后通过保存权重和偏置的最终训练值，形成 AI 模型。</p><p><img src="'+n+'" alt=""></p><h2 id="核心特点" tabindex="-1">核心特点 <a class="header-anchor" href="#核心特点" aria-label="Permalink to “核心特点”">​</a></h2><ul><li>分布式表示：信息不是存储在单一位置，而是分布在网络的连接权重中</li><li>并行处理：多个神经元可以同时处理不同的信息</li><li>自适应学习：通过训练数据自动调整参数，无需显式编程规则</li><li>非线性映射：能够学习复杂的非线性关系，处理高维数据</li></ul><h2 id="主要应用" tabindex="-1">主要应用 <a class="header-anchor" href="#主要应用" aria-label="Permalink to “主要应用”">​</a></h2><p>神经网络广泛应用于图像识别、语音识别、自然语言处理、推荐系统、游戏 AI 等领域。深度学习作为神经网络的扩展，通过增加网络层数和复杂度，在多个领域取得了突破性进展。</p>',12)])])}const f=e(l,[["render",o]]);export{m as __pageData,f as default};
