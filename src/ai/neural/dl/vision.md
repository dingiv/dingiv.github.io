---
title: 视觉
order: 30
---

# 计算机视觉
计算机视觉旨在让机器能够"看懂"图像和视频，这是人工智能中最接近人类感知的领域。从技术发展史看，视觉领域经历了从手工设计特征（如 SIFT、HOG）到传统机器学习（SVM + 特征），再到深度学习革命的完整演进。2012 年 AlexNet 在 ImageNet 竞赛中的突破性表现标志着 CNN 时代的到来，随后 ResNet、YOLO、Mask R-CNN 等架构不断刷新性能上限。2020 年之后，Vision Transformer（ViT）将自然语言处理中的注意力机制引入视觉领域，证明了纯 Transformer 架构在图像任务上的可行性。最近的扩散模型（Diffusion Model）则在图像生成领域展现出惊人的效果，Midjourney、Stable Diffusion 等产品让 AI 生成图像走进了大众视野。

计算机视觉的进步极大地扩展了 AI 的应用边界。自动驾驶汽车需要实时理解道路场景，识别行人、车辆、交通标志；医疗影像诊断系统能够辅助医生发现肿瘤、视网膜病变等异常；安防监控通过人脸识别和行为分析提升安全性；工业质检自动检测产品缺陷；内容审核平台识别违规图像；手机相机自动优化拍照效果。这些应用背后都是视觉算法的支撑，而且需求差异巨大——有的要求毫秒级响应（自动驾驶），有的需要极高精度（医疗诊断），有的要处理极端条件（夜间、恶劣天气）。

## 视觉任务
计算机视觉任务可以根据输入输出类型划分为几个主要类别。

+ 图像分类是最基础的任务，输入一张图像，输出属于预定义类别中的哪一类（如猫、狗、飞机、汽车）。ImageNet 竞赛推动了这个领域的发展，从 2012 年 AlexNet 的 15.3% 错误率到后来人类水平的 5% 左右，分类模型的准确率已经超过了人类。实际应用中，图像分类是相册自动归类、商品识别、场景理解等系统的基础。
+ 目标检测不仅要识别图像中的物体类别，还要定位它们的位置。检测算法输出的通常是边界框（Bounding Box）和类别标签。这个任务的挑战在于图像中可能存在多个物体、物体大小差异大、可能有遮挡。YOLO 系列算法（You Only Look Once）通过单阶段检测实现了实时性能，在工业界应用广泛；Faster R-CNN 等两阶段算法则在精度上更有优势。目标检测是自动驾驶、视频监控、机器人导航的核心技术。
+ 语义分割为图像中的每个像素分配类别标签，输出是与原图等大的分类图。与目标检测不同，分割不关心"有几个物体"，而是精确到像素级别——哪里是道路、哪里是人行道、哪里是车辆。这个任务对自动驾驶至关重要，车辆需要知道道路的精确边界才能安全行驶。FCN（Fully Convolutional Network）、U-Net 是早期的经典架构，DeepLab 系列引入了空洞卷积来扩大感受野。
+ 实例分割是更细粒度的任务，不仅要区分类别，还要区分个体。比如图像中有三只猫，语义分割只会标注"猫"，而实例分割会分别标出"猫1"、"猫2"、"猫3"。Mask R-CNN 是这个任务的标杆模型，它在目标检测的基础上增加了分割分支。实例分割在计数场景（如细胞计数、人群统计）和精细编辑（如抠图）中非常重要。
+ 关键点检测（Keypoint Detection），识别人体姿态、面部特征点。

AIGC 线路任务
+ 图像生成（Image Generation），从文本或噪声生成逼真图像；
+ 风格迁移（Style Transfer），将一张图的风格应用到另一张图；
+ 图像增强（Image Enhancement），超分辨率、去噪、低光增强；
+ 视频理解，动作识别、视频分类、时序定位；

## CNN
卷积神经网络（Convolutional Neural Network）是计算机视觉领域统治性的架构，从 2012 年到 2020 年，几乎所有视觉突破都基于 CNN。CNN 的核心思想是利用图像的局部相关性和平移不变性——图像中相邻的像素高度相关，某个特征（如边缘）在图像不同位置具有相同的意义。卷积操作通过滑动窗口在图像上提取特征，权值共享大幅减少了参数量，使得处理高维图像成为可能。

CNN 的发展历程体现了架构设计的演进。LeNet-5（1998）是最早的实用 CNN，包含卷积层、池化层、全连接层的经典结构。AlexNet（2012）通过 ReLU 激活、Dropout 正则化、GPU 并行训练，在 ImageNet 上取得突破。VGG（2014）使用更小的卷积核（3×3）堆叠更深的网络，证明了深度的重要性。GoogLeNet（2014）引入 Inception 模块，多尺度并行处理提升了效率。ResNet（2015）通过残差连接解决了深层网络训练难题，达到了 152 层，成为新的标准架构。

### 基本架构
典型的 CNN 包含卷积层、池化层、全连接层三类组件。

卷积层负责特征提取，通过卷积核在输入上滑动计算点积，每个卷积核学习一种特定的特征模式（如边缘、纹理、形状）。早期的层检测低级特征（边缘、颜色），深层组合低级特征形成高级特征（眼睛、汽车轮廓）。多个卷积核可以并行工作，每个核产生一个特征图（Feature Map），这些特征图堆叠起来形成立体输出。

池化层（Pooling Layer）进行下采样，降低特征图的空间尺寸。最大池化（Max Pooling）在局部窗口内取最大值，平均池化（Average Pooling）取平均值。池化的作用是减少参数量和计算量，同时引入平移不变性——特征轻微移动不影响池化结果。但过度的池化会丢失位置信息，这在需要精确定位的任务（如分割）中是个问题。现代架构中，池化逐渐被步长卷积（Strided Convolution）取代。

全连接层（Fully Connected Layer）位于网络末端，将卷积提取的特征映射到输出空间。分类任务中，全连接层输出每个类别的分数，经过 softmax 得到概率分布。但全连接层参数量巨大（例如 7×7×512 的特征展平后有 25088 维），容易过拟合。现代网络用全局平均池化（Global Average Pooling）替代全连接层，直接对每个特征图求平均，大幅减少参数。

### 卷积层
卷积是 CNN 的灵魂操作。给定输入图像 $I$ 和卷积核 $K$，卷积计算的是 $K$ 在 $I$ 上每个位置的加权和。卷积核的参数（权重）通过反向传播学习，训练好的卷积核会自动学会提取有用的特征——第一层的卷积核可能学习到边缘检测器，第二层学习到纹理模式，更深层的卷积核组合成复杂的物体部件。

卷积操作有几个关键超参数。卷积核大小（Kernel Size）通常选择奇数（3×3、5×5），这样可以对称地处理中心像素。3×3 卷积是最常用的选择，多个 3×3 卷积堆叠等效于一个大的感受野，但参数更少、非线性更多。步长（Stride）决定卷积核滑动的步幅，步长为 1 逐像素滑动，步长为 2 会跳过一些像素从而降低输出尺寸。填充（Padding）在图像边缘补零，控制输出尺寸是否缩小，Valid padding 不填充导致缩小，Same padding 填充使尺寸保持不变。

卷积层的设计有多个变种。空洞卷积（Dilated Convolution）在卷积核元素之间插入空洞，扩大感受野而不增加参数量，这在分割任务中很有用。深度可分离卷积（Depthwise Separable Convolution）将标准卷积拆分为深度卷积（每个输入通道单独卷积）和逐点卷积（1×1 卷积混合通道），参数量减少到原来的 1/8 左右，MobileNet 系列基于此实现轻量化。分组卷积（Grouped Convolution）将输入通道分组，每组独立卷积，ResNeXt 用这个技巧提升了性能。

## ViT
Vision Transformer（ViT）是 2020 年 Google 提出的架构，将纯 Transformer 应用于图像任务，打破了 CNN 的垄断。ViT 的核心思想是将图像分割成固定大小的图块（Patch），每个图块视为一个"词"，线性投影后得到序列向量，然后输入标准的 Transformer 编码器。这个设计极其简洁——没有卷积、没有池化、没有 CNN 特有的归纳偏置，纯粹靠注意力机制和大规模预训练学习视觉表示。

ViT 的成功依赖于大规模数据和预训练。原始 ViT 在 ImageNet-1K（120 万张图）上训练时，效果不如同等规模的 ResNet；但在 ImageNet-21K（1400 万张图）或 JFT-300M（3 亿张图）上预训练后，ViT 显著超越了 CNN。这说明 Transformer 的架构没有 CNN 那样强的先验假设（如局部性、平移不变性），需要更多数据来学习这些特性。一旦训练充分，Transformer 的全局注意力机制展现出 CNN 无法比拟的优势——每个图块都能直接与其他所有图块交互，不受感受野限制。

ViT 的架构细节体现了从 NLP 借鉴的设计智慧。图像分割成 16×16 的图块（对于 224×224 的图像，得到 196 个图块），每个图块展平成向量后通过线性投影得到嵌入向量。位置编码是必须的，因为 Transformer 本身不包含位置信息，ViT 使用可学习的位置嵌入，随机初始化后随训练更新。分类头采用 [CLS] token 的方式，类似 BERT，在序列前增加一个可学习的分类标记，最终输出这个标记的表示用于分类。

Swin Transformer 是 ViT 的重要改进版本，引入了层次化和局部注意力。标准 ViT 的全局注意力计算量随图像尺寸平方增长，难以处理高分辨率图像。Swin Transformer 基于 shifted window attention，在局部窗口内计算注意力，同时通过窗口移动实现跨窗口连接。这种设计使得 Swin Transformer 既可以作为通用骨干网络（Backbone）用于检测、分割，又保持了 Transformer 的全局建模能力。

ViT 与 CNN 的对比是视觉领域的重要话题。CNN 的优势在于归纳偏置强、数据效率高、训练稳定，适合中小规模数据；ViT 的优势在于全局建模能力强、可扩展性好，在大规模数据上表现更优。实际应用中，选择 CNN 还是 ViT 取决于数据规模、计算资源、任务特性。目前的研究趋势是融合两者优点，如 ConvNeXt 将卷积网络改造成 Transformer 风格的训练范式，CoAtNet 结合卷积和注意力。

## Diffusion
扩散模型（Diffusion Model）是近年来图像生成领域最具突破性的技术，其生成的图像质量、多样性远超之前的 GAN 和 VAE。Diffusion 背后的思想受启发于热力学中的扩散现象——如果向清水中滴入墨水，墨水会逐渐扩散直至均匀分布。逆过程则是从均匀噪声中逐步"去噪"恢复出清晰图像。这个思路在 2015 年就被提出，但直到 2020 年 DDPM（Denoising Diffusion Probabilistic Models）才在图像生成上取得显著效果。

扩散模型的训练过程是逐步向图像添加噪声，直到变成纯高斯噪声。具体来说，给定一张图像，我们多次添加小幅高斯噪声，每一步的噪声量由噪声调度表（Noise Schedule）控制。训练神经网络预测每一步添加的噪声，网络输入是当前带噪图像，输出是预测的噪声。训练目标是最小化预测噪声与真实噪声的差异，这个过程可以通过简单的均方误差损失来优化。

生成过程是训练的逆过程——从随机噪声开始，逐步去噪直到得到清晰图像。每一步用训练好的模型预测噪声，然后从当前图像中减去预测的噪声，得到稍清晰的图像。重复这个过程数百到数千步，最终得到生成结果。这个生成过程是迭代的，比 GAN 的一次前向传播慢得多，但生成的图像质量显著更高，训练也更稳定（不会出现模式崩溃）。

扩散模型的核心设计选择包括噪声调度表、网络架构、采样策略。噪声调度表决定每步添加的噪声量，线性调度从 $\beta_1$ 线性增长到 $\beta_T$，余弦调度则在开始和结束时变化更平缓。网络架构通常使用 U-Net，具有编码器-解码器结构和跳跃连接，能够同时捕捉多尺度特征。采样策略方面，DDPM 使用数百到数千步的马尔可夫链蒙特卡洛采样，DDIM（Denoising Diffusion Implicit Models）通过非马尔可夫过程将采样步数减少到 50 步甚至更少。

Latent Diffusion 是扩散模型的重要改进，在潜在空间而非像素空间进行扩散。直接在像素空间操作的计算量巨大，图像分辨率稍有增加就会导致显存爆炸。Latent Diffusion 先用编码器将图像压缩到低维潜在空间（压缩比通常为 4-8 倍），在潜在空间训练扩散模型，生成时再用解码器恢复到像素空间。Stable Diffusion 就是基于 Latent Diffusion，它能在消费级 GPU 上生成高分辨率图像，是扩散模型普及的关键。

扩散模型的应用已经超越图像生成。文本到图像（Text-to-Image）生成中，模型学习条件概率 $p(image|text)$，CLIP 等视觉-语言模型将文本编码为条件，扩散模型根据条件生成图像。图像编辑（Image Editing）任务中，可以通过修改扩散过程来实现图像修复、风格迁移、局部编辑。视频生成、3D 生成、分子设计等领域也开始应用扩散模型。扩散模型的成功证明了概率建模和迭代的去噪过程的强大，这为生成式 AI 开辟了新的方向。
