---
title: NLP
order: 20
---

# 自然语言处理
自然语言处理（Natural Language Processing）是人工智能的重要分支，致力于让计算机理解、解释和生成人类语言。NLP 的目标是在计算机和人类语言之间架起桥梁，使机器能够处理和分析大量的自然语言数据。在实际工程中，我们发现 NLP 系统的核心挑战在于如何处理语言的复杂性和歧义性，这与传统计算机视觉任务有着本质区别。

## NLP 的核心挑战
人类语言具有高度的复杂性和歧义性，这给计算机处理带来了诸多挑战：

1. 歧义性：同一个词或句子可能有多种含义
   - 词汇歧义："银行"可以指金融机构或河岸
   - 结构歧义："我看见了一个人用望远镜" - 谁用望远镜？

2. 上下文依赖：词义和句意依赖于上下文
   - "这个苹果很好吃"（水果）vs "苹果发布了新产品"（公司）

3. 长距离依赖：句子中相距较远的词之间存在语义关联
   - "我昨天在超市买的那个苹果，今天吃起来很甜"

4. 知识推理：需要常识和背景知识
   - "他打开冰箱，发现牛奶过期了" - 需要理解冰箱用来存储食物

5. 语言多样性：不同语言、方言、口语表达方式各异

## 常见 NLP 任务类型
### 分词
分词（Tokenization）是将连续文本切分成有意义单元的基础步骤，看似简单却直接影响后续所有任务的效果。中文分词的难度在于没有天然的词边界，不像英文用空格分隔单词，需要专门的分词算法如结巴分词、HanLP 来处理。

工程实践中，子词分词（Subword Tokenization）已成为现代 NLP 的标配。BPE（Byte Pair Encoding）通过统计词频合并最常出现的字符对，WordPiece 被 BERT 采用，而 T5 和 LLaMA 则使用 SentencePiece。这些方法能够有效处理罕见词和未知词，同时保持词表大小的可控性。

示例：
```
原文：自然语言处理很有趣
分词：自然 / 语言 / 处理 / 很 / 有趣

英文：Natural Language Processing is interesting
分词：Natural / Language / Processing / is / interesting
```

### 词性标注与命名实体识别
词性标注为每个词标注名词、动词、形容词等语法属性，是句法分析的基础。而命名实体识别（NER）则更具实用价值——它从文本中识别出人名、地名、组织名、时间等实体。工业界常用 BIO 标注格式：B (Begin) 表示实体开始，I (Inside) 表示实体内部，O (Outside) 表示非实体。NER 在信息抽取、知识图谱构建、智能客服等场景中有着广泛的应用。

示例：
```
The/DT cat/NN sits/VBZ on/IN the/DT mat/NN
那/DT 只/M 猫/NN 坐/VV 在/P 垫子/NN 上/LC
```

```
输入：苹果公司的CEO蒂姆·库克在北京发表演讲
输出：
  苹果公司 -> 组织
  蒂姆·库克 -> 人名
  北京 -> 地名
```

### 文本分类与相似度计算
文本分类是 NLP 中最常见的任务之一，包括情感分析、主题分类、垃圾邮件检测、意图识别等子任务。从工程角度看，方法经历了从传统的 TF-IDF + 朴素贝叶斯/SVM，到深度学习时代的 CNN、LSTM，再到 BERT 等预训练模型的演进。每个阶段在准确率、推理速度、数据需求上都有不同的权衡。

```
文本："这家餐厅的菜品非常美味，服务也很周到！"
分类：正面情感（Positive）
```
文本相似度计算则衡量两段文本的语义接近程度。搜索引擎用它来做查询和文档匹配，问答系统用它来找相似的历史问题，推荐系统用它做基于内容的推荐。具体方法包括基于词向量的余弦相似度、衡量字面差异的编辑距离（Levenshtein Distance），以及基于 BERT、Sentence-BERT 的语义相似度计算。

### 阅读理解与问答
问答系统可以分为抽取式、生成式和多跳推理三类。SQuAD 数据集推动的抽取式问答要求从原文中定位答案片段，而生成式问答则需要模型理解问题后生成新的答案文本。多跳推理更具挑战性，比如"《哈利波特》的作者的国籍是什么"这个问题，需要先识别作者（J.K.罗琳），再查询她的国籍（英国），这种推理能力在实际的知识问答场景中非常常见。

```
上下文：苹果公司成立于1976年，总部位于加利福尼亚州库比蒂诺。
问题：苹果公司的总部在哪里？
答案：加利福尼亚州库比蒂诺
```

### 自然语言推理
自然语言推理（NLI）判断两个句子之间的逻辑关系——蕴含、矛盾或中性。这个任务看似简单，实际上是衡量模型语言理解能力的重要基准。给定前提"一个女人在喝咖啡"和假设"一个人在喝饮料"，模型需要判断这是蕴含关系。NLI 能力直接影响对话系统、事实核查等下游应用的效果。

```
前提：一个女人在喝咖啡
假设：一个人在喝饮料
关系：蕴含（Entailment）
```

### 机器翻译
机器翻译的发展是 NLP 进步的缩影。早期的基于规则的方法依赖人工编写的翻译规则，扩展性极差。统计机器翻译（SMT）时代基于大规模平行语料统计翻译概率，但需要复杂的特征工程。神经机器翻译（NMT）采用 Seq2Seq + Attention 架构显著提升了翻译质量，而 Transformer 的出现则彻底改变了这一领域——Google Translate 和 DeepL 等产品都基于此架构。实际应用中，歧义处理、文化差异、罕见词翻译和语序流畅性仍然是需要持续优化的方向。

### 文本摘要与对话系统
文本摘要分为抽取式和生成式两种。抽取式摘要从原文中选取关键句子组成摘要，实现简单但连贯性较差；生成式摘要能够生成新的总结性文本，流畅性更好但容易出现事实错误。新闻摘要、会议纪要、文献综述是典型的应用场景。

对话系统则更为复杂。任务导向型对话系统（订票、客服）需要精确理解用户意图并完成指定任务，闲聊型对话系统追求开放域的自然交互，而问答型对话系统则聚焦于准确回答用户问题。一个完整的对话系统包含自然语言理解（NLU）、对话管理（DM）和自然语言生成（NLG）三个核心模块，每个模块都有不同的技术路线和工程挑战。

### 文本生成评估
文本生成任务的评估一直是个难题。BLEU 用于机器翻译评估，通过计算 n-gram 匹配度来衡量生成文本与参考文本的相似性。ROUGE 则用于摘要评估，侧重召回率而非精确度。Perplexity（困惑度）是语言模型的传统评估指标，但这些指标与人类主观判断的相关性始终有限——生成"这个苹果是红色的"和"这个苹果是红色的水果"，BLEU 分数可能相同但信息量完全不同，这也是实际工程中需要结合人工评估的原因。

## NLP 神经网络架构演进
深度学习时代之前，NLP 主要依赖词袋模型、TF-IDF、N-gram 等传统方法。这些方法存在明显局限：词袋模型丢失词序信息，TF-IDF 无法捕捉语义，N-gram 则面临维度爆炸和稀疏性问题。

Word2Vec 在 2013 年的出现是一个转折点。Skip-gram 和 CBOW 模型将词映射到稠密的低维向量空间，首次让机器能够捕捉词的语义关系——"king - man + woman ≈ queen" 这个著名的例子展示了词向量空间的线性结构特性。虽然 Word2Vec 本身是静态词向量（每个词只有唯一表示），但它为后续的上下文相关表示奠定了基础。
