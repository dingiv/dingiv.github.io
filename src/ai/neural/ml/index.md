---
title: 机器学习
order: 10
---

# 机器学习
机器学习（Machine Learning）是人工智能的一个分支，它可以让计算机从数据中自动学习规律，而无需显式编程。更进一步讲，通过分析某一类数据及其相关因素的统计学分布规律，从而在以后通过相关因素预测该类数据。机器学习，它学习的是一个**纯函数映射关系**，我们可以通过这个关系，在知道相关因素的情况下，预测出目标数据的值。机器学习项目最终所形成的**模型**，就是这个映射关系的载体和成果。

```
target = F(related_factor_1, related_factor_2, ..., related_factor_n)
```
F 就是我们期望使用机器学习所探寻的关系或者模型。这个**函数**的结构通常是一个类似数学公式的结构，接近于数学意义上的**函数**，此时，编程中的*函数*和数学中的**函数**，少有地能够如此贴近和统一——该*函数*是*纯函数*，不进行 IO 操作。

## 建模流程
机器学习的基本工作模式：
```
准备数据 ---> 特征工程 ---> 模型训练（机器学习） ---> 模型评估 ---> 模型调优
```

1. 准备数据
   - 数据获取（爬取、数据库、公开数据集）。
   - 数据探索（EDA）：查看分布、缺失值、异常值。
   - 数据清洗：处理缺失值、异常值、重复值、格式统一。

2. 特征工程（最重要、耗时最多的环节）
   - 特征提取：从原始数据中生成新特征。
   - 特征预处理：标准化/归一化、编码（One-Hot、Label Encoding）、处理类别不平衡。
   - 特征降维：PCA、LDA 等，降低维度、去除噪声。
   - 特征选择：过滤法、包裹法、嵌入法（如 Lasso、树模型特征重要性）。
   - 特征组合：领域知识创造交互特征。
   - 核心：特征工程结合业务知识，能显著提升模型上限。

3. 模型训练
   - 划分数据集：训练集（70-80%）、验证集、测试集。
   - 选择合适算法（从简单 baseline 开始）。
   - 训练模型，调整超参数。

4. 模型评估
   - 分类任务常见指标：准确率、精确率、召回率、F1、AUC-ROC。
   - 回归任务常见指标：MSE、RMSE、MAE、R²。
   - 使用交叉验证（K-Fold）获得更稳定评估。

5. 模型调优
   - 超参数调优（Grid Search、Random Search、Bayesian Optimization）。
   - 集成学习进一步提升性能。
   - 保存模型（pickle、joblib、ONNX），上线部署。

## 准备数据
- 样本（Sample）：一条数据记录，对应表格中的一行，也称为“实例”或“示例”。
- 数据集（Dataset）：多个样本的集合。
  - 训练集（Training Set）：用于模型学习规律的数据，通常占 70%-80%。
  - 验证集（Validation Set）：用于调参和选择模型（可选，有些流程用交叉验证替代）。
  - 测试集（Test Set）：用于最终评估模型泛化能力的数据，训练过程中不可见。
- 特征（Feature）：描述样本的属性或变量，对应表格中的列（除标签外）。也称为输入变量、自变量。
- 标签/目标值（Label/Target）：需要预测的变量，对应表格中的目标列。
  - 在监督学习中，训练集带有标签，测试集通常也需标签用于评估。
  - 无监督学习中无标签。

核心公式：

```
target = F(related_factor_1, related_factor_2, ..., related_factor_n)
```

- F：机器学习要学习的模型（映射函数）。
- related_factor：特征（输入）。
- target：标签/目标值（输出）。

### 示例

西瓜数据集（周志华《机器学习》经典例子）

| 编号 | 色泽 | 根蒂 | 敲声 | 纹理 | 脐部 | 触感 | 密度  | 含糖率 | 好瓜 |
| ---- | ---- | ---- | ---- | ---- | ---- | ---- | ----- | ------ | ---- |
| 1    | 青绿 | 蜷缩 | 浊响 | 清晰 | 凹陷 | 硬滑 | 0.697 | 0.460  | 是   |
| 2    | 乌黑 | 蜷缩 | 沉闷 | 清晰 | 凹陷 | 硬滑 | 0.774 | 0.376  | 是   |
| 3    | 乌黑 | 稍蜷 | 浊响 | 清晰 | 稍凹 | 软粘 | 0.634 | 0.264  | 否   |
| 4    | 青绿 | 硬挺 | 清脆 | 模糊 | 平坦 | 硬滑 | 0.657 | 0.198  | 否   |
| ...  | ...  | ...  | ...  | ...  | ...  | ...  | ...   | ...    | ...  |

- 色泽、根蒂、敲声、纹理、脐部、触感、密度、含糖率 → **特征**。
- 好瓜 → **标签/目标值**（分类任务：是/否）。


## 特征工程

特征工程是将原始数据转化为更适合模型学习的特征的过程，常决定模型上限。

### 常见方法

1. 数据预处理

   - 缺失值处理：删除、填均值/中位数、插值、模型预测填充。
   - 异常值处理：剔除、截断（winsorize）、变换。

2. 特征缩放

   - 归一化（Normalization/Min-Max Scaling）
     - 将数据映射到 `[0, 1]` 或 `[-1, 1]` 区间。
     - 公式：$x' = \frac{x - x*{min}}{x*{max} - x\_{min}}$
     - 适用：数据有明确边界、算法对数值范围敏感（如神经网络、KNN）。
   - 标准化（Standardization/Z-Score）
     - 转换为均值 0、方差 1 的分布。
     - 公式：$x' = \frac{x - \mu}{\sigma}$
     - 适用：大多数算法（如线性模型、SVM、逻辑回归），对正态分布假设敏感时更优。

3. 编码

   - 类别特征编码：One-Hot、Label Encoding、Target Encoding。
   - 文本特征：Bag-of-Words、TF-IDF、Word Embedding。

4. 特征选择与降维

   - 过滤法（方差、相关系数）、包裹法、嵌入法（Lasso、树模型重要性）。
   - PCA、LDA 等降维。

5. 特征构造
   - 组合特征、数学变换（log、对数）、分箱、交互项。

特征工程原则：结合业务知识，迭代实验，不断验证效果。

这个版本补充了缺失内容、修正了小错误（如“浊向”→“沉闷”示例）、扩展了表格，并保持结构清晰。如果你想继续添加部分（如数据探索 EDA、常见评估指标），随时告诉我。

## 模型训练
使用 Python 的数据分析三件套（NumPy、Pandas、Matplotlib）和 scikit-learn 机器学习库。

针对于不同的任务类型，采用不同的训练算法。

### 监督学习
- 训练数据带有明确标签（目标值）。用于学习特征 → 标签的映射关系。
- 子类：
  - **分类**：标签为离散类别（如垃圾邮件/非垃圾邮件）。
  - **回归**：标签为连续数值（如房价预测）。
- 典型算法：线性回归、逻辑回归、决策树、随机森林、SVM、KNN、XGBoost 等。

### 无监督学习
- 训练数据无标签。用于发现数据内在结构、模式或分布。
- 子类：
  - **聚类**：将相似样本分组（如客户分群）。
  - **降维**：压缩特征维度，保留主要信息（如 PCA）。
  - **关联规则**：发现数据项之间的关系（如购物篮分析）。
- 典型算法：K-Means、层次聚类、DBSCAN、PCA、Apiori 等。

### 半监督学习
- 训练数据中只有少量有标签，大量无标签。
- 目标：利用无标签数据辅助有标签数据提升模型性能。
- 常见场景：标注成本高（如医学图像标注）。
- 典型方法：自训练、协同训练、图-based 方法、生成式模型。

### 强化学习
- 无明确标签，通过与环境交互获得奖励/惩罚信号。
- 目标：学习最优策略（action policy），最大化累计奖励。
- 核心组件：代理（Agent）、环境（Environment）、状态（State）、动作（Action）、奖励（Reward）。
- 典型算法：Q-Learning、DQN、Policy Gradient、PPO 等。
- 应用：游戏、机器人控制、自动驾驶、推荐系统。

## 模型评估
训练完成之后，评估模型的拟合效果。

欠拟合（Underfitting）指的是模型过于简单，无法有效捕捉数据中的真实规律，导致训练集和测试集上的误差都较高。产生欠拟合的原因通常包括模型容量不足、训练不充分或特征信息不足。解决的方法可以是增加模型的复杂度、丰富特征或者延长训练时间。

过拟合（Overfitting）则是指模型过于复杂，不仅学到了数据的规律，还把训练数据中的噪声和异常情况也进行了拟合。这会导致模型在训练集上表现很好（误差低），但在测试集上效果差（泛化能力弱）。过拟合常见的原因有模型容量过大、数据噪声较多或样本量不足。应对方法包括使用正则化、Dropout、早停法、增加数据量、做数据增强或采用交叉验证等技术。

理想情况下，模型应达到恰当拟合，即在训练集和测试集上均能取得较低且接近的误差，表明其既能学到数据的主要规律，又具备良好的泛化能力。
